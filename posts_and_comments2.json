[
    {
        "post": "/r/dataengineering/comments/1gq4k9m/hmm_work_culture/",
        "comments": "I wish my desk looked like that. Open plan is shit.\nYeah no joke. My best office setup was a private room with 3 devs in it. We dialed in the lights, had speakers playing chill coding music, closed the door and talked shit about managers. But my 2nd best setup was a cubicle. Enough space to decorate a bit, make it more comfortable (lamps, plants). Even had a bit of space for someone to hang out and have a beer (and talk shit about managers, quietly). On the odd day I'd even kick my chair back and take a quick nap in peace. Now I'm in open plan and it's just a circus. I can see and smell whatever the 6 people around me are doing, everyone keeps bumping into my chair, I can hear 3 separate conversations from across the building about metrics or roadshows or whatever conquest Henry had over the weekend. Gen X got it right. Cubes were a great compromise for in office work. I'll even take TPS report cover pages back at this point.\nBest part were our Italien offices. 5 people too many in the room. Everyone bumps into your chair. It is 40 degrees and the AC is turned off cause otherwise the powerline shorts out. And every few minutes you get a heart attack cause people start screaming at each other, which is actually just a normal civilized Italien conversation.\nHaha this is so accurate. Haven't worked with Italians but I have been in a ski gondola with them and it sounded similar.\nMan you said it, all those stuff right there are what I have to deal with everyday, these trendy open plan office schemes need to hit one big reset button to give people their own space back How in the fresh hell can someone truly focus with all this rowdy stuff going on, especially if it's a coding job where you spend most of the time in your own head\nLove this. Now you seem like a fun person to work with! Always have to look out for those back stabbers at the office. I like to toss a little bait on the trap to test the waters and quickly see who Im having beers with and who Im avoiding at all costs.\nI hear you on tossing the bait. I like to throw out a little dry sarcasm about doing bullshit work, but then just doing a good job at it anyway. Usually a couple of people notice and we figure out a way to make the bullshit work less bullshit and then grab beers after. An example here is when PMs wanted time tracking to the closest 30 minutes for every ticket. We just wrote a script to look at duration of ticket life and pick a random number between 50 and 80 percentile of that range. Turns out that number was close enough, and our team won an award for being the most diligent with efficiency. Script ran daily for 2 years until PM left and we poured champagne as we shut down the cron job.\nSame. Impossible to have Teams calls at desks due to disturbing others, so people are always running around with a laptop in their hand desperately trying to find somewhere to take a call because all the meeting rooms are full.\nI totally agree and I feel like nobody talks about this enough, I would be far more willing to come into the office if I had a slightly private space to work in rather than open plan desks In a regional office where Im never directly working with people around me and Im always on Teams mob programming (you know, actually collaborating), so Im either distracted by people around chatting, or people on the call are asking me to mute myself because they hear chatter in the background\nCome to office to sit on your machine and zoom with your teammates cross continent and country Fuck Andy Jassy\nLol hassle free\n\"For few to stay rich, many must stay poor\"\nYou get a free fruit basket too ! Fun fact: when Im in the office, I get less done cause some colleague love to talk  a lot\nHonestly, if I was told to come back to the office I'd also talk more. Why be more productive if the company doesn't reward productivity.\nIm just creating moments of serendipitous creativity\nI don't really think they care about productivity. I'm definitely working less time in office than in home because of the long commune and other issues. They just want to bug people whenever they want because in-person communication is indeed faster than chats. And they probably want to remove those who work two jobs -- while management comfortably sits on multiple boards and jobs.\nMy current client doesn't have enough seats at the office, so the team rotates the days they go in. The most pointless return to office imaginable as all meetings still have to be via Teams.\nBut the water cooler talks? What about the _water cooler talks_???? (same - weve axed two offices and moved to hoteling. fortunately most arent required to come into the office ever.)\nI feel it's about: 1. Bullshit metrics so execs get good feelies that \"\"\"collaboration\"\"\" is happening 2. Justify their high rent costs, as with no one there, they can't justify such space. Instead of leaning into it and getting smaller offices, they go back to their boomer mindset of THE WAY I DID IT, KIDDO\nyeah right! Jokes is on them stupid managers. No one is actually collaborating even when we are sitting next to each other.\nHow could we? It sounds like a street market in those open plan offices. If leadership cared about metrics, they would go back to team/squad-based, closed-door offices.\nIf they did stuff at the office (like team events, lunches or get togethers). Then coming into the office wouldnt be that bad. But the fact you go in and ALL of your meetings or on zoom, teams or whatever else.. makes it pointless.\nIn person meetings are usually super inefficient anyways. There is quite literally no value add unless you are doing some kind of physical demo. 98% of the time you are sharing digital visual aids. People are always late from the last meeting. Except of instead pf just two clicks to change over to next mtg, they have to pack all thier shit up and run to the next meeting. Depending on where that is, could easily be 15 mins late to your next meeting. And then people let meetings run wayyy over so you have attendees that are so late it would have made more sense to reschedule, and everybody else showed up in person for that one asshole to make the whole effort a moot point. Add to that Boomers who still cannot use basic tech like a projector, an HDMI cable plugged into a laptop to screen share, or that Teams chat/ Slack is a thing and is much better than dropping by at your cube and interrupting literally everything you are doing to solve his problems instead of yours. Offices are obsolete.\nI understand not everyone can, but my company did this and I just told them no. Work, as obnoxious as it is to enforce, is a two way arrangement where you should be enforcing your own boundaries. This gets easier the further away from entry level you go. I wish I'd known I could've had this relationship with work when I first started out, but it's not taught to us or made apparent because it's obviously better for everyone else if you don't have or advocate for your own interests. Anyway, I did this song and dance a handful of times a month (i.e. sitting in a cubicle in online meetings all day), and then when the company announced we were going to full RTO for everyone, I just said no. I can quit and get a better job tomorrow though, so definitely weigh the potential pitfalls of your no before you give it.\nMind numbingly dull\nIf a an artisan builds Notre Dame in the woods, did anybody notice? Office corporate reminds me of childhood. You may have had parents where if not there observing the productive activity you fill your day with, because they're at work, it's assumed nothing happened in that gap. The insecurity of managers is similar. The nagging doubt that their role is in jeopardy if their teams aren't blazing hamster wheels off their track. Seeing the hamster wheels running eases those insecurities. I think it's worse in companies without a \"What did you get done this weke?\" culture where managers are hands on with their teams. In an environment where managers often can't do the work of their team, the manager itself may not be needed, and in those cases insecurities go wild.\nAnd everyone gets to pay an extra $500/month in fuel costs."
    },
    {
        "post": "/r/dataengineering/comments/1gopcxa/enjoy_your_pie_chart_karen/",
        "comments": "In what world do the end users acknowledge the engineers unless something is wrong\nWhen nothing is wrong, but the software doesn't match their own incorrect assumptions and they call it broken\nI love to deliver data that shows line going down when my 10 end users have already told an executive that line going up based on nothing\nWhy is your prediction jumping so much, it must be wrong as it never happened before. IDK guys, maybe turn on literally any news showing frozen Texas and you will know. Why does a simple junior data engineer explain data to a senior market analyst with triple my salary?\nMan, how I love spending my afternoon proving the numbers are right, and marketing's campaigns really suck at converting. It's not like I have a backlog that stretches deep into 2026, am I right?\nMy colleagues dont look at the dashboards\nYep, most absurd joke here is colleagues actually giving a shit about dashboards.\nHOW DO I GET THIS INTO EXCEL!!!?!\namen to that\nEveryone join the hocon revolution now\nHocon?\nHocon is a configuration format. Assumes that humans are flawed and will likely make mistakes and allows leeway. Though its not serializable, it can be parsed effectively.\nLink?\nCan refer this https://github.com/lightbend/config/blob/main/HOCON.md Fun fact: Apache Airflow uses the pyhocon library for parsing too\nI thought this was going to be a joke about how terrible pie charts are.\n, this is hilarious"
    },
    {
        "post": "/r/dataengineering/comments/1gb8ndm/databricks_threatening_me_on_monday_via_email/",
        "comments": "Thought yall might enjoy this. Why do they have to do this on a Monday, Id be more okay if this email was sent on a Friday \nBecause it is mostly a joke and should cheer you up at the beginning of the week Although I am sure they believe in it.\nHaha fair point.\nDamn thats crazy, anyway\nLow-key, the context the auto complete has is wild. Joining two CRM tables with terrible column names, it knew which column was the key between tables - I assume based on the structure of the key (keys to certain tables are prefixed with a code). I.e. all I typed was inner join some_table and auto complete dumped the rest out immediately. Maybe it was just coincidence but the more I use this the more I rethink my career...\nThats weird, I disabled autocomplete because it was terrible. It would often suggest to do read.parquet even though we only have delta tables in unity catalog. It would suggest to use .show instead of .display.\nIf knowing the syntax of a join query was all that protected your job, I'd be concerned, too. Perhaps knowing which two tables needed to be joined (and why), based on discussions with stakeholders and a review of project requirements and business objectives, had something to do with it.\nLmao EdGy. If you read again, it's not the syntax I am making note of, it's that it knew what data was each column to guess at the join criteria. Part of working with data is sometimes picking up tables with little to no documentation or SMEs, profiling, mining and determining how to navigate an unknown data model. The point is, databricks is shouldering a lot of that work while I am in the discovery phase of a new dataset.\nDoesn't quite a bit of that assume the person working on it before you named the data in a sensible format? Or that you have good technical meta-data? I think AI is at the part like when you first look at a data set to figure it out. If the name is shit, then it is going to be tougher.\ni used to guess column names for a living... now look at me, out on the damn street. if only i understood hOw ThE wOrLd WoRk3d\nNot sure what you mean, my guy. Upvotes agree.\nTrue but it's like drag and drop or any other tools that suppose to make it so easy for you to do something. Once in a while there are something stupid that AI spits out and you have to jump in to save it. And I think people have this weird perception that any job would be the trait itself. A job is about solving a specialized problem and if you can still do it when AI is out, who cares which tool you are using. At least at my org, our DEs are busy as a bee fixing backlog. For all I know, it will help these folks instead of replacing them. And if there is AGI that is human in the eyes of law. God help us. And a job/career is the last thing humanity should be worried about \nSame here. And people that haven't used o1 really have no clue. I drop in microservices full code, ask how it works, to identify code smells and ways to refactor it and to productize it by adding telemetry, logging etc. It's pretty great for this stuff.\nu/extracoffeeplease How long before it eliminates data engineers all together do you think?\nRefactoring or writing some code isnt the whole job. No one can tell, but for sure you're safer in your job if you're less of a 'single responsibility microservice' yourself. I think juniors, who are typically told to do only one thing like bugfixing or coding, will have rough times ahead. Companies will focus on hiring more senior as they can do all the stuff the machine can't as of yet.\nYeah, anyone who feels this isn't a game changer are wrong. It would vastly change how the world works. In 10 years, we have no idea what the jobs landscape will look like.\nu/king_booker how long before it eliminates all data engineers do you think?\nNo idea mate. I don't think it eliminates all, but the team sizes would reduce. People who think nothing will change are in denial. Best case scenario is that we work alongside AI, which I think is the future in the next 2/3 years\nTo bless us! Why? AI = More Data Assets, Cataloging, Governance, Storage Medium, API's, etc. to engineer as \"... all new AI ready\" Data Products! Woohoo!!! More stuff to learn thanks. Not kidding. This is what we love and do, gents. Embrace and lean into a new salary band. \"AI Data Engineer\" thank you!\nDatabricks are fully intent on milking the AI grift as much as possible.\nThats was a typo OP, they are cumming 4 u.\nNot as threatening as [DuoLingo](https://i.imgur.com/HIEV9Dg.jpeg).\nDatabricks AI assistant isnt perfect (none of GenAi assistants are), but its wild how quickly its improving. I welcome it, saves me hours of grunt work each week. Its not going to write error-free pipelines for you automatically, but it can help generate PoCs and spot syntax errors quickly (even when its the reason we had syntax errors in the first place). My favorites are using it to summarize code (helpful when dropping into someone elses notebook for the first time), adding comments where missing or incomplete, applying a standard formatting, and generating commit notes. Edited grammar\nAre you using Databricks AI more like Intellisense in Visual Studio? Does this mean we are re-inventing the wheel but with AI?\nIt can do Intellisense-like things. But its a lot more than just that capability. Just like in VS Code there is an AI assistant that helps with higher level questions (what steps should I take to accomplish xyz, summarize this notebook, do you spot areas for performance improvements, etc.). Then there is a coding assistant that works with each notebook cell or SQL query to generate or complete code in that cell/query. Both AI implementations were pretty rough initially, but Id say they get things right about 70% of the time. And even when its wrong sometimes it can introduce helpful ideas and functions you might not have been aware of. Its hard to get true metrics on accuracy, because the AI is aware of the code in your notebooks and the data in your workspace. Im not sure how Databricks manages all of that (query results come too quickly imo to be a RAG implementation, maybe just feeding prompts into long context LLM models?). But the result is impressive. The other factor is the more you work with AI (not just Databricks AI) the more you learn what its good and bad at, you start intuitively providing better prompts which further improves the quality of your results. Edited for typo\nIn many ways, it sounds like we are trading one set of problems for another.\nIm pretty sure theyre just putting out a shitty version to troll you.\nok \nAI is coming after every one of us. Time to go for manual technical roles.\n\nX 4,, 6 cd y. Ewwe;-):-)\nThreat level 000\nIm shitting databricks over here\nThey teeerk err jobs!\nI'm using databricks' ai every day. We are fine...\nIt's a halloween themed post?"
    },
    {
        "post": "/r/dataengineering/comments/1gstga9/any_netflix_des_on_here_what_happened_last_night/",
        "comments": "Oh this was a fuck up well north of our pay grade lol. Clearly resource scaling was not working correctly. Could been a third party issue, scaling config problem, anything really... who knows. My guess is Netflix tried to step into the mass streaming service realm because the rights to this fight came across their desk and they didn't want to say no even though this kind of thing is not their specialty in the same way it is for YouTube, Twitch, etc. So they told their architects to figure it out and... they didn't.\nImagine working at a company where the listed LinkedIn job pay range is up to 720k/yr and a problem is considered well north of your pay grade. I say this in jest x) I work at a company where multiple accounts run 8 digit bills for AWS and it's mind boggling. I can't possibly fathom how complex the issue was for a show of this scale.\nI was curious and did a little research. Netflix opted out of adopting industry standard CDNs early on when they had a shitload of marketshare instead building their own called Open Connect and the play kind of backfired at this point but they are in too deep (sunk cost fallacy) to stomach the price tag on what it would cost for Akamai or some other industry leader in the content delivery network space.\nWhat a pissing contest does to a mfer\niceberg?\nIts common at a lot of places and is something that [even has a Wikipedia article](https://en.wikipedia.org/wiki/Not_invented_here).\nSomeone probably bagged a nice project in their CVs as well as some large paychecks. I always dreamed to be those kinds of people.\nIt's not really sunk cost fallacy. Migrating away from their bespoke solution into some other one that wasn't built to fit into the rest of their architecture is not cheap.\nStill sunk cost fallacy. Whilst the cost to migrate might have been eye watering, it would still have been preferable over this spectacular fail.\nThey should start applying some of their no rules rules principles\nNetflix does that for everything.\nIts not the first live event they fucked up. They tried to do a Love is Blind reunion live. It started 70 minutes late bc of technical issues and then many users still lost connection.\nJeeze. Was that recent? Even less of an excuse in that case.\nIt was around this time last year iirc\nI mean they have been testing the waters with live content. Theres a live David Chang cooking show and WWE is coming in Jan. Wrestlemania is going to be a similar load. This was a stress test that completely failed.\nI imagine they are more worried about Christmas Day NFL games\nFrom what I read (Ill edit if I can find the source) the viewership was well above what they expected. NFL games draw about 30 million and the Paul/Tyson event was well north of that.\nThey have attempted live streaming before and also fucked it up. Most recent from my memory was the love is blind live reunion that ended up being delayed by like 2 hours because Netflix couldnt handle it.\ntheir aws bill was about $27mn a month btw lol\nSource? Thats actually super lean when Apple is known to pay $1B plus per year\nyeah there's no way...... <10 in infra cost per subscriber per month? I'd be very surprised.\n27m a month might literally be for one just service lol\nfound this explanation, i think this is the reason https://www.reddit.com/r/cscareerquestions/s/48DWJHXArp\nI had issues and my ISP is Google Fiber. It seems suspect to me that Google had an issue, not impossible, but rarely have I had any issues. Last I heard Netflix works mostly on AWS and I transfer 100s of gigabytes and sometimes terabytes of data to/from AWS from my local connection fairly regularly without any issues.\nI can't take that response seriously. \"Localized ISP servers?\" What year is it? It sounds like someone that actually understood infrastrucutre tried to explain it in child like terms to the poster.\nYou can read [this Netflix blog](https://about.netflix.com/en/news/how-netflix-works-with-isps-around-the-globe-to-deliver-a-great-viewing-experience) where they talk about putting servers at various ISPs to deliver content faster.\nThat is true. My friend used to work at a local ISP with the infrastructure team that hosted the Netflix delivery servers. They have local distribution servers everywhere.\nThe trick behind the magic is usually disappointing.\nThis is a fact, Ive worked with ISP and they do have Netflix caches for speeding up streaming\nCan you explain it better then?\nNot a DE issue but it seemed like a load balancing problem. Too much traffic and poor distribution. Live streaming is not what Netflix specializes in and it showed. Hopefully there will be an engineering blog about this.\nCould you elaborate?\nData engineering is transforming and manipulating data. Taking messy, large heaps of data, ingesting it, joining and tweaking it into fact and dimensions tables and loading it for end users or reports the business can use to make decisions. This was not a data engineering issuethis was an issue balancing the load of streaming to 6 million people at the same time. Imagine 6 million people trying to use your computer to play a game. Hows that gonna work? Its not. Now imagine you have thousands of servers, that can distribute the required compute power to serve all those users. When more people come, it spins up more servers and services to handle the added compute needed. This is where they had an issue.\nDef not a data engineers jobs. Thats the Cloud Architects problem lol\nGuessing with most of their content they can cache everything before streaming it out. With live events you cant do that without a big delay\nTheir caching design is really cool, worth googling. Essentially they have physical cache hardware at backbone centers. Was unique at the time but has become more common\nWas the viewership of this higher than other live events that other services have hosted? F1, Olympics, Superbowl, NFL games, Facebook live, Twitch, YouTube live, World Cup. It ain't the first time a live global event was streamed...\nI dont know how Netflix did . But similar streaming service Hotstar from India did it very well . Take a look https://youtu.be/9b7HNzBB3OQ?si=XK6yJgcWOySQBG_J\nYeah hotstar is goat when it comes to these things. Full HD even with 50 to 60 million streams at times\nThat's the quality I pay for. I don't know about how good they are with 4k\n4k streaming is tough. The bandwidth is orders of magnitude higher than HD so you're now doing heavy compressions.\nThanks for sharing!\nthis is where I guess PRIME VIDEO is going to eat them\nlol\nIt is not a DE issue; more of a CDN, caching, load balancing, etc. Some people mentioned that the streaming worked well on their phones; it could be a matter of splitting the resources differently.\nCant wait for them to fup the NFL in 5 weeks\nWhatever the issue was, they need to come clean and let the customers know the RCA and what they're doing to prevent it for future live events.\nViewership was massive, at a sizeable ISP our peering traffic was up over 900%.\nThey did it on purpose in case Mike went off script and bashed Jake's face in. Easier to censor it that way.\n\nNetflix needs to work on its automated failover strategy"
    },
    {
        "post": "/r/dataengineering/comments/1gn7d8b/how_to_benefit_from_lean_data_quality/",
        "comments": "I don't understand this post. I'm a huge advocate for ELT over ETL and your criticism of ELT is much more applicable to ETL. Because in ETL transformation steps take place inside ingestion steps, documentation is usually barely existent. I've refactored multiple ETL pipelines into ELT in my career already and it's always the same. Dredging through ingest scripts and trying to figure out on my own why certain transformations take place. Not to mention, the beauty of ELT is that there is less documentation needed. Ingest is just ingest. You document the sources and the data you're taking. You don't have to document anything else, because you're just taking the data as is. Then you document your transform steps, which as I've already mentioned, often gets omitted in ETL because it's part of the ingest. As for data quality, I don't see why data quality would be less for an ELT pipeline. It's still the same data. Not to mention, you can actually control your data quality much better than with an ETL. All your raw data is in your DWH unchanged from the source, any quality issues can usually be isolated quite quickly. In an ETL pipeline, good luck finding out where the problem exists. Is it in the data itself? Some random transformation done in the ingest step? Or during the business logic in the DWH?\nInteresting, because with storage price becoming cheaper, it's usually a good idea to land the source data as-is, and do profiling/discovery after to create your pipeline/modelling accordingly.\nMaterializing a copy of your data can be done equally easily using either ETL or ELT, so is not really a differentiator. However, at sufficiently massive volumes it can still be a challenge to store & retain a copy of the source data.\nThere are tools to avoid full materialization though. You can do logical materialization then parse out what you need.\nWhat do you mean by full vs logical materialization? A view vs persisting data to a table?\nYes, I know. You're describing ELT, i.e. agreeing with me. Unless you meant to agree with me, in which case your wording is confusing as it appears to disagree.\nI agreed with you. What I meant was that your insights are interesting.\nSorry, I misinterpreted your post then.\nI agree 100%\nPreach\nThat's not been my experience - unless we're talking about projects that people just hacked together. Regarding data quality: * Readability: With ETL you may use a general-purpose programming language like Python. Rather than have 600 lines of clumsy field transforms all mashed together you can separate each to separate functions. * Unit testing: Languages like python & ruby enable easy unit testing. While you can hypothetically perform unit testing with SQL the reality is that the setup is too much work. Almost nobody does it, and when they do they do so sparingly. * Raw data: super-valuable to keep around, and easy to do for both ELT & ETL. For ETL it's more likely to be kept in files and queried using something like Trino or Athena. Which works perfectly fine. Regarding Documentation: * For ETL solutions using canned packages this usually comes with the solution. * For custom ETL solutions it may not, and may require the engineers to build it. However, there are a few short-cuts for them: what I like to do is simply generate a markdown or HTML page from all my transform functions and publish this. It includes the docstring, names & types of input & output columns, describes exceptions and formats, and also has a link to the unit-test source code so my users can click on that to see what the tests look like. While my users are usually not programmers they have found this to be incredibly valuable - because they can actually read the unit tests. * For ELT much of the documentation focuses on data linage - since data pipelines can sometimes be as much as 30 model layes deep in DBT (yeah, I've seen this), and it otherwise becomes a nightmare to know where any data came from. But the documentation is often very soft on exactly what transforms are happening to a field - since the transforms are just mashed-together SQL rather than separate UDFs or functions. Imagine nested case statements, substrings & strpos along with some verbose built-ins. That crap is prone to human-error, difficult to read, and seldom well-documented.\nYeah - we land our data first. Most of it pipes into GBQ from there. Then we use dataform for our workflows. Dataform has assertions so we can choose to fail for data quality issues. It also has unit testing. Having all of our domain logic in SQL/JavaScript has been truly game changing for our team. Like others have said - most issues are upstream. Engineering teams should find them, then elevate them to the business, data scientists, or whoever owns the data for remediation. Even with streaming data, the tooling has grown. You can centralize transformation logic with ETL, but then you have logic at your access layer and your input layer. Hard to manage unless you merge them. We hardly even document our data anymore. It's documented in the pipelines via configuration, and that documentation is in an artifactory so it's uniform. From there I just enable a few APIs and boom we have lineage, and everything feeds through to a doc system. There's tooling beyond that which can capture your transforms for you. It's almost 2025. This is all really easy.\nI agree, ELT is perfect and reject management is easy. ETL is so pre-2010. I guess the meme maker made a typo.\nRemember SSIS? I don't want to.\nI still deal with it. Using it for strictly telecom. Every else a sql job with sprocs. Convert to Python when possible.\nIt was such a nightmare. I will say, when choosing tech, I avoid shiny objects. I need to hire engineers that can work with a tech, and I don't want to change EVERY tool I use every two years. Python and SQL are great. I hate no-code pipelines.\nYeah I found this picture confusing. ELT is way better than ETL for documentation and data quality. Just on its face, you typically have the code documenting how to get data into the transformed state whereas you are likely to not have this if your ETL process relies on stored procedures and triggers. Edit: downvotes are perplexing here. Im agreeing with the person Im replying to. Are you all really suggesting ETL is better than ELT for data quality???\nWho on earth upvotes junk like this?\netl or elt...is a trade off, none is a silver bullet. Also documentation issues will appear in both\nNever heard of LDQ. I need to look it up\nI don't understand hardly any of these posts. From my POV, \"ETL\" is just the name for the placeholder for data ingestion. Whether you do ETL or ELT depends on individual data feeds and the two are not mutually exclusive. One type of data may be better with ETL while another is better using ELT. It isn't a data ecosystem decision, but more of a feed by feed decision. Most everyone here talks about documentation from a technical standpoint. That is the easiest part of documentation. Linking the business metadata up with the technical metadata is the goal. Consider how you look for data in your warehouse. It isn't \"I'm looking for an int\" but \"I'm looking for net sales\". This is just one piece of the data documentation.\nwe solved tabs v spaces so people need another utterly worthless debate to hang on to\nIn my experience ETL vs ELT...the quality issues actually occur more predominantly prior to the E. So depending on your situation if you're a small nimble startup/nimble team or a huge enterprise with a lot of disparate sources and some being external partners ...changing sources with little coordination/documentation..TL or LT...a pipes going to break somewhere. ETL is schema on load. There is a designed model that is being loaded to ELT is schema on read. You figure out what you want when you consume. ELT has a chosen trade off for agility and speed...but harder to govern depending on the rate of changes and how tight or loose your quality checks are between your producers and consumers. People, Process and Tools. This is addressed more so by Process and People and less so much by Tools (Unless said tool is Data quality/Data Governance focused)\nPeople who dont use ETL and ELT as synonyms are silly.\nOr as a typo /s"
    },
    {
        "post": "/r/dataengineering/comments/1glu70w/top_skills_for_data_engineers_data_from_100/",
        "comments": "Ok. This is a lot better than the last one lol Good job.\nThanks lol. Hope to add some value - your feedback was correct - last list was too high level.\nyou can do something similar to market basket analysis to find out which skills are requested in combination\nThis is doable will take some work, can try over the weekend\nI'm trying to put something together to help with this, but man, these job postings love to conflate skills which are widely separated. Modelling data is not the same as managing a data lake / cluster etc.\nThis is a really good idea!\nMan I really need to branch out from just being a SQL expert. Finding the motivation has been tough though. This sub makes me feel bad for not having the drive to learn on my own time lol.\nJust learn some python, then learn business and you'll be fine\nInstructions unclear, I now own a pet store specialized in snakes\n\nAWS is actually very interesting and I think its high time you should diversify your skills for sure!\nAny strong clusters?\nCould you clarify what you mean by clusters? Groups of technologies being used together?\nYes exactly. Having a list is not that helpful because I will probably not use those techs in random combinations. But if you can cluster the skills into usual job profiles (or the jobs by skills) then you can give us insights into what \"collection\" of skills to study to have a good chance to get a role.\nI love how low communication and collaboration are.\n\ngreat job\nNo R.\nNot surprising IMO.\n3 mentions\nThis is something awesome. This activity actually helps in identifying the key skills and hacking through the interview.\nIn my completely unscientific vibes test, Hadoop should be way higher than that. Not because it's a useful skill, it's not... but I feel like I see an unusually high number of positions that ask for experience in it. Did any F500 companies ever have Hadoop clusters? It was pretty niche back in the early 2010's back before companies wanted to be \"dAtA dRiVen\". By the time F500 companies got data science fever, Hadoop was already obsolete. I just think its weird that so many postings ask for an obsolete skill that the company has never once needed at any point in history.\nHadoop is pretty much dead at this point. Buried next to SOAP and XML\nI agree with you 100%, this is solely based on job posting on LinkedIn. Could be based on disconnect between HR and the teams. Or maybe they are posting these roles under titles different from data engineer.\nCan you explain why you think Hadoop isnt necessary? What scale does a company need to be at for it to make sense?\nCloud computing and general advancements in hardware made Hadoop obsolete. You don't need to have a giant cluster of physical computers to work with big data anymore. You can rent and pay as you go with a cloud provider. It's also somewhat debatable if anyone actually NEEDED Hadoop in the first place. Look at the average companies Databricks instance. 90% of them could probably run on an on-prem Postgres or MSSQL instance.\nFrom job descriptions that are likely bullshit post that stay for weeks ( or reposted) in this market and they cant seams to fill them in. You cant trust this shit anymore.\nOnly 100?\nI got to around 350 companies to get these 100 jobs\nReally interesting point\nDoes this look like a full-stack Data skills position, not just a Data Engineer position, lol? I mean, PowerBI is for Data Analysts, while ML is for Data Science/AI. No way a DE knows all of this. Big companies usually have separate DA/DS/DE teams, so you just need to focus on DE skills. While in many small companies, dues to lack of funds, usually they force you to do all the DA/DS works, even you're a DE\nThese are very low frequency I have no idea why these are mentioned though\nI have even seen front end technologies mentioned in JDs of Data Engineer multiple times in my country.Not really a DE position,possibly due to this handled by HRs.\nCan we get a bot to automatically create a resume with the most popular skills? Where is the data from?\nThis is all data from LinkedIn, Ive mentioned the excel at the end.\nChatGPT\nHow did you extract key skills from job description? Genuine question as i am working on something similar\nI found out the top occurring key words and then created a list of keywords to look for. Not scalable of course but did the job for me.\nHow is this possible ? I do all of this, and i dont even work for a Fortune 500. Phhh .. amazing\nCan you tell me more? Do you work at a small company?\nThanks\nThanks\nBy this measure Id say GCPs gaining ground on the other hyper scalers.\nBigQuery ftw\nCan you divide this by experience level if possible?\nData engineering skills are so varied now like being a jack of all trades in data\nHonestly every role doesnt need you to know everything. But when you are preparing you have to learn everything and its good to build that foundation. Also once you join a company you will be maybe using 3/4 of these maximum.\nCool! Anyone care to do the same for Europe? I bet Azure would be higher than AWS and GCP would me virtually non existent"
    },
    {
        "post": "/r/dataengineering/comments/1gmto4r/pydata_nyc_2024_in_a_nutshell/",
        "comments": "That's interesting! Here in Amsterdam, its duckdb over polars. Both have their origins in The Netherlands, I believe. So does Python. Odd coincidence... Any clue why polars is apparently getting more buzz?\nPolars' API is very similar to R's dplyr. People like those design choices.\nAgreed, R's dplyr is a joy to work with and polar is bringing similar experience to python.\nYou may find Ibis interesting, coming from R: https://www.reddit.com/r/dataengineering/comments/1gmto4r/comment/lw8lrg7/ Some of the more experimental additions to the Ibis ecosystem, like IbisML, are also very inspired by Tidyverse (specifically Recipes).\nThere was actually an excellent talk on Ibis yesterday, it was probably one of my favorite ones. The speaker did a really good job.\nI get that, from my initial explorations, I really liked the API. I also appreciate that polars follows the Unix philosophy of doing one thing and doing it well. Duckdb sometimes feels like it's trying to do too much.\nCan you elaborate? In what sense is DuckDB doing too much In comparison to Polars?\nIt's now also a virtualization layer to other databases for instance. Polars just does single node in-memory computation really well, coupled with good read and write functionality. If my understanding here is behind the times, let me know, I haven't fully kept up.\nIf you like dplyr, you would likely also find Ibis very familiar: https://ibis-project.org/tutorials/ibis-for-dplyr-users And then you have the added benefit that you can choose to use Polars, DuckDB, or whatever else under the hood.\nand pyspark\nAlso pyspark\nI believe it's because the programming model is more similar to pandas/spark, plus the name sounds like it would be another bear just like pandas. My two cents.\nlol I never even put the bear thing together. Grizzly is probably next.\nThe name is quite interesting: *\"OLAP Query Engine implemented in Rust\"* OLAP.rs -> POLA.rs -> POLARS\nGrizzPy\nRecent GPU advantages too, tho I havent used that.\nA few would include: * It's written in rust which makes it fast. * It has some neat options. One recent one is an experimental GPU engine which is supposed to be [very fast](https://www.reddit.com/r/dataengineering/comments/1fj0hh8/released_today_up_to_13x_faster_polars_with_new/)\nWere there any DuckDB related talks at PyCon Amsterdam? - https://www.youtube.com/playlist?list=PLGVZCDnMOq0reU2lzNZCn9obkyRVaSnpF I did not notice any from the titles. DuckDB has its own DuckCon though, so people may focus more on doing talks there instead of PyData. - https://duckdb.org/2024/08/15/duckcon5.html - https://duckdb.org/2025/01/31/duckcon6.html\nI was just referring to the general conversation, but I would've expected them there, tbh.\nAh okay, thought I may have missed some. Hannes' talks are always very interesting. (looks like the most recent one is from Posit Conf https://www.youtube.com/watch?v=GELhdezYmP0)\nDuckdb requires using sql, whereas in polars you just need to use python. Many people working on data science dont have a huge programming background and usually just know python, so its easier to adopt. That doesnt mean that duckdb isnt as good as polars, in my experience both are great\nI would say this should really work the other way around. Python is multiple times more involved than SQL\nGood point, but part of me is really surprised they never bothered to learn SQL. It's not as if it's hard...\nPolars is a well built modern data analysis library, just too bad, there's no real reason for us to change atm. The volume we are seeing most of the time is just too small to bother picking up something new.\nI am happy to hear the traction lol. I hate pandas with a passion. I would love to see the day polars overtake pandas in usage in the wild.\n> I hate pandas with a passion. Could you expand on that? I have a love/hate relationship with pandas, but I have been hesitant to invest the time in finding out if polars would suit me better.\nThe syntax is much cleaner. The method calls do what you expect them to do. The most important difference is that polars doesn't have the stupid index. I cannot stress how fucking problematic the index is in pandas. All anybody wants is to aggregate a column, group by, and have the label actually be above the aggregation.\nLong time (former) pandas user here, make the switch, give it a few weeks, youll never look back. Its wonderful and better than pandas at almost every use case.\nThis is what has happened to about half of our pandas users now. They've tried polars for other reasons and have stuck with it because it is better even if if the speed or memory gains aren't needed.\nI've worked through the User Guide: https://docs.pola.rs/ The `Expressions` chapter, as well as `Lazy API` and `Migrating > Coming from Pandas` are must-reads. \"If your Polars code looks like it could be pandas code, it might run, but it likely runs slower than it should.\" Example: `df[\"some_col\"][0]` vs `df.select(pl.first(\"some_col\")).item()` The second code can run with the Lazy API, improving the speed of your code ;)\n! RemindMe 7 days\nEssentially echoing what other replies are saying :) Coming from a software engineering background: The first thing that I HATE is pandas' own branded version of \"index\". Everywhere else (databases, caches, etc) index refers to an auxiliary data structure to speed up data lookup. It does not change compute's outcome. It is purely a performance characteristic. Pandas index/indices, however, represent something totally different. Different index DOES change the computation outcome. https://docs.pola.rs/user-guide/migration/pandas/ this summarizes a lot of the gripes I have. E.g.: > Polars aims to have predictable results and readable queries, as such we think an index does not help us reach that objective. We believe the semantics of a query should not change by the state of an index or a reset_index call.\nIsn't duckdb's API predominantly SQL? If so, are you really surprised it got less coverage at a python event?\nNo one is surprised. Duckdb has a Python api, which is probably how its mostly used. But the point of the meme was really meant to highlight the very palpable shift from pandas/numpy to polars/duckdb. As in polars and/or duckdb were mentioned in almost every talk, Ritchie Vink was there with his old coworkers, who gave a talk on switching from pandas to polars. Whats (pleasantly) surprising is the amount of mindshare polars is getting and how mainstream it has become.\nIt has a very good dataframe api as well\nWhich api are you referring to? In the official doc I cannot find any dataframe api (except for the SQL synthax).\nDuckDB has docs on using Ibis as a dataframe API: https://duckdb.org/docs/guides/python/ibis.html They also have docs for their experimental Spark dataframe API: https://duckdb.org/docs/api/python/spark_api.html\nthe relational api\nIbis\nI think they're referring to [https://duckdb.org/docs/api/python/relational\\_api.html](https://duckdb.org/docs/api/python/relational_api.html)\nDuckDB >>>>> Polars\nNot if you're used to using PySpark.\nDuckDB has a Spark API now: https://duckdb.org/docs/api/python/spark_api.html\nI just discovered the same thing. Although it looks like you beat my comment by about five minutes: https://www.reddit.com/r/dataengineering/comments/1gmto4r/pydata_nyc_2024_in_a_nutshell/lw8jmef/\nCan you or someone explain how this would be something useful? I mean lets suppose im using pyspark, why would I want to switch to duckdb? Unless it runs duckdb in a distributed way which will be really cool actually\nI was responding to somebody who mentioned that DuckDB is less familiar than Polars for somebody familiar with the Spark API, implying that DuckDB only had a SQL interface. The choice of engine should be separate from the choice of interface. All the Spark dataframe API for DuckDB does is let you use the Spark interface with the DuckDB engine. Now, why would you want this? If you're using PySpark in a distributed setting, Spark may continue to be all you need. If you're running some of these workflows locally (or using single-node Spark) maybe you could use DuckDB, which generally outperforms Spark in such situations, without changing your code. Maybe you even want to develop and/or test locally using the DuckDB engine and deploy in a distributed setting with the Spark engine, without changing your code.\nI am. And I still like DuckDB more\nI didn't know that DuckDB has python APIs. That pushed me to read about it a bit more. What I also didn't know is that one of those python APIs is a [Spark API](https://duckdb.org/docs/api/python/spark_api). And that API is based on PySpark. So it looks like my initial comments were incorrect. Although the Spark API is currently experimental based on their documentation.\nSomeone is tracking the PySpark implementation work on the DuckDB Github discussions: - https://github.com/duckdb/duckdb/discussions/14525 # PySpark API - https://github.com/duckdb/duckdb/discussions/14725 # Python Expression API\nIt has has an R api that is supposed to be pretty good.\nI feel like people dont get how powerful duckdb is.\nIt's an in processes in memory columnar OLAP RDBMS (with none of the management requirements or server based config needs) with vectorized execution, holy moly it's soooo good. Leverages all the power that a columnar relational/SQL based execution system has to offer not afforded by at DataFrame first approach. The SQLite of OLAP systems. I think most SWEs and DS's people are just too used to Pandas that's my theory. For people from Data Analytics - SQL First I just feel more naturally attracted to duckdb.\nCan you elaborate? I've personally found the polars api much easier to use. Also I've personally found the async reader much better in polars than duckdb (though i tried pre 1.0 for duckdb).\nThe database part of it really makes it stand out to me.\nDo you mean the write aspects? As polars fits the read parts of a db pretty well.\nAnd clickhouse is miles ahead lol. Just use clickhouse-local.\nThose experienced and knowledgeable in both: when would you use one over the other? If you wanted to make one standard at your workplace which would be easier to implement / standardize ? I've heard Duckdb is rarely used in production, is that true?\nDuckdb is a database, polars is a framework for manipulating data. An analogy is duckdb is similar to SQLite and polars is similar to pandas.\nDuckDB is also a framework for manipulating data. It has a dataframe api that is very good. And whenever there is something that is hard to do using the dataframe api, you can switch over to sql (as in you just do it in the next line), and you can switch back when you want to. It can also treat Polars/Arrow/Pandas/Numpy dataframes as tables and query them without you having to do any conversion. So you can super easily join a pandas dataframe with a polars dataframe with a duckdb table.\nYou can use duckdb to manipulate your data, just as you would any database. One thing that makes duckdb special is its interoperability with other frameworks like pandas and arrow\nOkay so if your team is used to doing data manipulation with a python API Polars is better. If they are used to SQL, Duckdb is better.\nYes, but they also do different things. You wouldnt persist your data in polars for the long term, but you might with duckdb.\nI guess if you're using Duckdb then you're going to use the flavor of SQL that Duckdb comes with. Where Polars reads data into memory from some DB your team is using.\nPolars also has a sql api that transcribes the sql to its own pipeline using their expression and contexts. I sound like a shill for it but I really like that dual approach aspect depending on the task Im given.\nCan it take SQL from any dialect and transcribe it to its pipeline? Also: are there good resources or tips for running Polars in production?\nSometimes I mix and match. Might read in duckDB, zero copy to pandas/polars, output to parquet. Ive only done small tests but duckDB is usually faster reading data\nIve used it in production, just not as a normal database. Duckdb works great for storing huge amounts of data fast, which makes it a good replacement for SQLite in C/C++ programs that hit its limitations (e.g. tables with many columns)\nDatafusion doesn't get enough love around these parts.\nSeems like data fusion is the slowest on most benchmarks Ive seen? Thats whats stopping me from using it\nIbis bench puts it pretty on par with duckdb. I'd take all the benchmarks with a massive grain of salt though. A lot can change just based off your setup. I think polars/duckdb/datafusion are all within spitting distance of each other in terms of speed.\nAre you referring to these benchmarks? - https://duckdblabs.github.io/db-benchmark/\nI believe Ibis has released some benchmarks using polars, datafusion, duckdb that look decent.\nIsn't datafusion the engine behind the scenes in duckdb?\nNo, it is not. DuckDB is its own engine (written in C++).\nDuckDB and Polars are different techs, and it's weird that this this sub is even comparing them\nWhere can I watch the videos? Don't see them on their YouTube channel.\nThey usually get uploaded over the months after the event\nIt will probably be December when they are uploaded. It took ~1 month for the PyData Amsterdam videos, there were 2 Polars talks if you're interested: - https://www.youtube.com/watch?v=yYAVrVMGaMY - https://www.youtube.com/watch?v=BgnPgssga90 Full Playlist: - https://www.youtube.com/playlist?list=PLGVZCDnMOq0reU2lzNZCn9obkyRVaSnpF\nOoOoooo thanks so much\nAlso they both support arrow so you can zero-copy query a polars data frame using duckdb, which is crazy fast\nLove me some polars... Lazy loading columnar formats to work with datasets bigger than you can fully load in memory, yes please. Every time I use pandas I get frustrated with syntax and how single threaded the whole thing is.\nI gave a talk at PyData NYC yesterday, and yes I was one of those who lifted up Polars over SQL. My talk was about how to write programs using LLMs - it works great for Polars, but not so great for SQL right now.\nLLMs work better for Polars syntax than for SQL? I'm surprised to read this - given that SQL has been around for a lot longer, I'd have expected a lot more training data to be available Is it because there's too many variations of SQL?\nI didn't watch your talk, but it's interesting to hear different perspectives on LLMs for data code--some people say it's better at Python, others say it's better at SQL. I previously spoke to somebody from Turntable (https://www.turntable.so/), who also mentioned LLMs are better at generating Python, but they use Ibis to be able to choose the execution engine of choice.\nWould you care to share a link or slide(s) to illustrate that? I have found the opposute generally speaking, so I would like to learn more.\nThe video will be out soon. For SQL, i introduced this benchmark: [https://bird-bench.github.io/](https://bird-bench.github.io/) SotA is 74%, humans are at 93%. Imperative languages with lots of docs are currently better than \"mathemtical\" declarative languages like SQL.\nCan someone eli5?\nPolars is Pandas on steroids DuckDB has data storage solution\nIs duckDB sqlite on steroids?\nNo. Theyre designed for very different tasks. Polars and pandas are also arguably designed for different things, although there is a lot more overlap.\nThey are both inprocess so very little config needed and you don't need a \"server\" to run them or log in etc. But as a result ACID compliance, especially concurrent users, is not what they are specialized for (DuckDB and SQLite). DuckDB is the Columnar OLAP counterpart to the Row Oriented OLTP system that is SQLite. Both are in-memory with options to persist if necessary. I think as Duck is natively in-memory it uses different data access methods and data structures than a traditional database like Postgres would use which are disk based + memory buffer pool. Here's a paper [https://mytherin.github.io/papers/2019-duckdbdemo.pdf](https://mytherin.github.io/papers/2019-duckdbdemo.pdf) from one of the authors of DuckDB\nSame\nSide question on this: are the talks online, by any chance? Or will they be?\nThey will be in the next couple of months\nPolars ftw. I created a very extensive etl pipeline without writing a single word of SQL. Pure code. Love it\nSql is code\nIt's such a major red flag when people treat avoiding SQL as a goal. SQL is the default choice for good reason and you better have a real reason not to use it before picking something else. Learning is a valid reason, but still.\nbeing a data professional and avoiding SQL is like living in Germany and not speaking German\nThats a funny analogy! . I'm inclined to agree with you. But I don't know SQL that well compared to py, all the skills i gained were the stuff I learnt on the job out of necessity. Only now i realised I have been doing DE work on DA pay lamao\nThere are reasons to chose to use dataframes with an API over sql. For some users and use-cases it is absolutely valid to avoid using SQL for a project. Although I agree that SQL is so widespread that it is very useful to have some familiarity. If you would like to see a comparison of dataframes/sql see this discussion here: https://www.reddit.com/r/dataengineering/comments/101k1xv/dataframes_vs_sql_for_etlelt/\nThank you! My use case is kind of niche and building my project in terms of dataframes was so much easier for me. Reduced my development time by quite a lot.\nYeah, I really only agree with what the top comment replied in that post. The problem lies in complexity and orthogonality. It's far too easy to think your requirements are more complex than they are and to shoot yourself in the foot with other languages. They have their place, but their place is firmly second to SQL, unless SQL is inappropriate. In contrast, it's pretty difficult to write garbage SQL because there are only a few ways to accomplish any task in SQL. I would rather take strong type and check constraints in the RDBMS and concise SQL over unit testing and breaking up queries into fragmented logical components in the name of modularity, when those components are only ever used a handful of times. Why bother writing thousands of lines of code when SQL declaratively states what you are doing with the data, and abstract how that work is done? You aren't going to beat the execution engines. And if another better engine comes along, you can transpile the SQL to that new dialect, sometimes even on the fly and not bothering with a rewrite (sqlglot is a great python package for this). I think there are elements to DRY that can apply to SQL, but my general philosophy is don't worry about DRY until you have something repeated 3 times. I'm a strong proponent of idiomatic approaches to SQL like CTEs/temp views, [SQL UDFs](https://www.databricks.com/blog/2021/10/20/introducing-sql-user-defined-functions.html) (which have native performance, because it's basically inlining), and [lateral column aliases](https://www.google.com/search?q=databricks+lateral+column+alias&oe=utf-8) to reduce duplication and overall code size. In our companies cloud migration I cut our SQL code size down to ~10-20% of the prior lines of code while making it much faster. I think people who shun SQL don't know how far its come recently and aren't embracing modern SQL workflows. And I only say all this because I used to be a hardline Dataframe person. Then an architect had me rewrite the same solution side by side in pyspark and SQL and my mind was blown at how much simpler the SQL version was, I just needed to get good at SQL.\nIt wasn't my goal to skip SQL. Python APIs are just easier to use.\nGreen flag, IMO. SQL is a trashheap of a language. We should've had alternatives years ago, but large companies throw their weight around to squeeze us for money. It's why it's a good thing that Oracle is slowly being supplanted by Postgres.\nLike I said, red flag. SQL is an straightforward and extremely orthogonal approach to data transformations. It isn't the right tool for pulling from APIs, but unless you have to deal with things like schema evolution or customizeable user defined schemas, your T in ETL/ELT should probably be SQL. It is also pretty unlikely that you can choose a better language than SQL for performance, because execution engines are so good and SQL is so portable that you can switch to different backends pretty simply.\n> SQL is the default choice for good reason Reason being that the Relational Model is crazy powerful, not because SQL is actually a good language. SQL was doodoo from the very start. The only reason it's the \"default choice\", is because IBM, Oracle and other such companies threw their weight around to keep SQL on #1. SQL is like C++ - crazy powerful, but a complete pain to use in larger codebases, so you stick to a clean subset and hope it doesn't hurt too much. That's why evoiding SQL is _not_ a \"major red flag\". Speaking of SQL alternatives: [EdgeQL](https://docs.edgedb.com/database/cheatsheets/select) seems pretty nice.\nHaving a programming language even as basic as Python gets you functions, classes, modules, testing frameworks, dynamic code etc. and is sometimes just a lot easier than having to deploy something like dbt just to get this sort of thing.\nPolars on Pyspark is a really processing friendly tool. Its at least 10x faster so I do understand the hype\nAre you referring to running Polars on Spark's driver node? I am not aware of any other way to use Polars with Spark.\nI use palantir software, there you can use it. Not sure how it works there\nThey're not usable for the same things, SQLite would struggle for the workloads that DuckDB excels at and vice-versa.\nWhy though?"
    },
    {
        "post": "/r/dataengineering/comments/1go7jq9/4_month_data_engineering_study_plan_based_on/",
        "comments": "This seems insane at 4 months, Month 1 alone can span multiple months. This is similar to SeattleDataGuys 100 Days of Data Engineering which is really used more for advice than anything. The DSA component alone could span weeks. I've done an intensive study going 8 - 10 hours a day for weeks earlier this year following similar roadmaps and I just want to say for most people even averaging 6 days a week maybe 8 hours a day it will be challenging to complete in 4 months. Especially if they're starting off from 0. I'd recommend people take this as with all roadmaps a a general guidance and don't get too discouraged if instead of 4 months it takes 8 months. Edit: honestly was being a bit liberal with 8 months if you're starting from 0. Honestly 8 months is if you're coming from a Data Analyst SQL only/Excel background. Think 12+ months for those coming with no skills in either databases or programming. Again I don't want people to read any of this and get discouraged that in 4 months they realize \"whoa wait I'm no where close to completion am I just slow?\" No you are most certainly NOT slow! Data Engineering is absolutely NOT an entry position. Most people coming in are either from Data Analytics, Data Science or Software Engineering so they come in with a lot of background necessary and they STILL have to learn more to be a DE. I suggest to be kind to yourselves. I certainly wasn't to myself and it does not help. It's a long journey, just keep at it!\nI have 5+ YoE and have been grinding leetcode for a few weeks and I can just now consistently solve python easys. Going from \"what is a SQL?\" to interview ready could legitimately take a year on it's own lol\nAgree everyone has a different background. I had a CS background with analytics experience so it took me 4 months. Take your time!\nJust curious, with this experience, what did you do month 1 specifically?\nExactly\nWell, if youre just starting, dont bother with Scrapy or Puppeteer yet. BeautifulSoup is super easy for basic HTML. For JavaScript-heavy stuff, try Selenium. And if you want some new AI tool, AgentQL is worth checking out. Big scrapes on major sites are risky. Use proxies or, better yet, look for an API first.\nNot related to my comment but totally agree. Scrapy is more \"intermediate\" from what I've seen. Get by as much as you can with Requests and BS for those starting out. Also don't use ORMs. [https://youtu.be/jVz8mBRPOmY?si=H2IoZ\\_uxUcbWZKeT](https://youtu.be/jVz8mBRPOmY?si=H2IoZ_uxUcbWZKeT) this a video I liked a lot when first learning about scraping from a data focused youtuber.\nAppreciate the video link. gotta love the good data-focused YouTubers out there.\nI think realistically 6 - 8 months is doable - given you dont start off from zero. But I totally agree DE is definitely not an entry position.\nPersonally think you should move orchestration, ci/cd, elt/etl up. As soon as you know enough SQL and python you could do POC dagster/airflow + dbt thing that can probably really dig your teeth into. Then you can \"productionize\" your SQL and python on a 2nd pass. Then you can apply like best practices stuff for python projects like ci/cd and containerization and the like.\nAgree good option!\nGreat! I need to prepare myself for DE job interviews (or at least an internship) till June as it is going to be my summer vacation after my 3rd year of university. I had the topics listed out for preparation and have already covered the concepts listed in month 1 but having a structured roadmap like this will surely help and it also gives me confidence hearing from you that it is indeed possible to do this in 4 months. One suggestion: Can you please write down your preferred Udemy courses for each category you recommend Udemy for? Udemy has tons of courses which can get overwhelming to choose from.\nI think in general the most popular course which has hands on Udemy does the job. Few I remember - - Airflow - Marc Lamberti - PySpark - Prashant Kumar - Anything AWS - Stephane Maarek For python and sql I did Datacamp + Leetcode\nThanks! I know you said to go for the most popular course but it would be aweso,e if you can give a specific suggestion for Azure. I cannot sign up for AWS without a credit card but Azure gave me credit for being a student so I have to go with Azure.\nhttps://codebox.code.blog/ This blog will help.\ngreat stuf man. was looking for something like this i have 2.3 YOE was planning to switch dont know what to do thanks for this\nAppreciate it!\nfor apache airflow you mentions udemy for it can you tell me which course should i prefer i have udemy free acess from my org\nMarc Lambertis - Airflow hands on course is the best!\nThank You, one more please help For DSA what are the Topic which i learn and resource last help\nThis is really great stuff man! Kudos! Need advice: I have 2 yoe working with Pyspark, Sql, AWS. What are the areas I should focus more on? Can I DM with more details please? Would be of great help.\nI think you have the key technologies down. Maybe more certifications/projects & networking. For sure Ill be happy to help!\nThank you so much\nBruh how am I supposed to do this at the same time as doing my da job\nTake your time bro no hurry, you already got SQL and python in the bag - youll be good!\nWhat level do you assume people are at when starting this study plan (I.e total beginner or experienced and just wanting a refresher)? It reads like youd only be spending 3-4 days at most on each tool or topic (especially in month 3)\nMostly for beginners. I assume 20 hours of effort per week.\nI'm from a Data science background and have academically worked on ML and DL , recently also have done projects based in GenAI. I'm planning to get into an entry level DE job tho since I find it more interesting. I have intermediate knowledge in Python and SQL, I've also been doing azure (Mostly Databricks to transform data and storage services) and also learning Azure data factory. What more should I focus for an entry level position in the current job market in India :)\nDo projects and certifications, learn PySpark\nI have been doing PySpark and doing a project based on a udemy course (Azure Databricks and Spark for data engineers:Hands on project by Ramesh Retnasamy) . I am planning to also do Airflow from the udemy course you have mentioned above. But I still feel I'm under prepared and there have not been many opportunities even though I've been applying for the past 2 months.\nThen I would recommend to network more - make a list of 100 companies you are interested in. Reach out to Senior data engineers and Lead Data engineers. Have a 30 minute call with them. Ask them more about what they do, they will themselves reach out to you if they have positions open.\nSure will do that Thank you so much:)\nThanks\nIs this helpful for Someone from non computer science background ? My wife wanted to start\nThanks for this\nCool post. Not a DE but just trying to understand what is the reasoning behind understanding Data Structures and Algorithms. Each of the other things in phase 1 are all practical things whereas this seems more theoretical.\nThey can be used for efficient data processing more over every big tech company has a DSA 1st round in their interview process for data engineers"
    },
    {
        "post": "/r/dataengineering/comments/1galqy8/i_found_some_data_to_ingest_at_a_grocery_store/",
        "comments": "I will take 2 pounds of fresh data please!\nNeeds thorough cleaning though\nCheck it for duplicates first\nIts Raw data need to be ingested into the Datalake\nMy pipeline is ready\nConsumption based pricing\nNum num.  (I think my brain needs some sleep)\nAnd like most of the data - it's garbage\nIngest to fridge, do cleaning, transform to digestable format then expose them on dish for comsumption. This is good approach for someone want to understand DE job : ))\nData is a vegetable in Bengal. Instead of writing the word in Bangla script they have written it in English alphabets. Still funny though.\nBut is it good data?\nCurate with garlic or curry? \nI think it will require some data cleaning.\nI can't stomach this much data.\nWhich leaves are these\nData \nFr?? Lol\nI came to know its call Data in Bangla. \nDamnn.... Perfect for this sub\nLookout for stale data, thank me later\nIs there an actual plant/produce called data? Why is that written there?\nYou wouldn't download a data!\nThat's structured data, not as cheap as it used to be but still a good deal."
    },
    {
        "post": "/r/dataengineering/comments/1gt7r1b/python_crash_course_notebook_for_data_engineering/",
        "comments": "cool , will check out\nAppreciate it  Let me know if there is any scope for improvement!\nExcellent job!!\nAppreciate it \nGreat timing. Thanks OP!\nGreat work\nThank you so much for this, I am preparing for interviews and this is such a good help to have\nThanks!!!\nThanks OP\nThanks for putting this together!\nSubscribed!\nNote\nAmazing work my friend. People like myself will find this really helpful. Thanks for this \nAppreciate it \nSuper useful for data analysts, data scientists and data engineers alike. Thanks for sharing!\nAppreciate it thanks!\n![gif](giphy|l3V0sNZ0NGomeurCM)\n![gif](giphy|pHb82xtBPfqEg)\nGreat course, excactly what I needed for Data Engineering!\nAppreciate it!\nNice\nIs there a way to bookmark a post ?\nNvm found it\nThank you, been looking for this\nThis is awesome!"
    },
    {
        "post": "/r/dataengineering/comments/1gnor9c/launching_a_free_sixweek_data_engineering_boot/",
        "comments": "How much did all these bot comments cost?\nLol good question. Jesus, it's insane, every other comment is just the remind me bot..!\nEveryone is excited for this? Just making a splash by releasing tons of content here\nThank you, I'm actually exciited for this. I get why remind me comments can be annoying though.\nIs your proper course priced assuming my work is paying? Id love to buy your course but I feel like the price is quite high\nIts $200 for just the content. If you want the live boot camp experience please pay me for my time and effort and compensate my mentors who help you get to the next level. Live boot camps have a lot of people to pay\nIt's 200 a month for anyone reading\nIt also comes with free access to AWS, Trino, Confluent, Iceberg, weekly design meetups, the ability to deploy your own production airflow pipelines and 250 hours of content. $200 one time fee wouldnt work for this.\nBoooo\nAh I didn't know about the 200 for the content! Thanks\nI miss the old days where people would teach for free on YouTube and not try to push courses all over.\nZach, how would you compare your free bootcamp to others, like Zoomcamp and Joe Reiss free course? What do you think makes your YT bootcamp more unique?\nI talk about what scales in big tech from my own experience which isnt something in either of those\nRemindME! 3 days\nAwesome. Cant wait\nRemindme! 6 days\nyou can't pay $0? Okay..\nThe subscription is about 125$/monthly\nIm releasing a free YouTube boot camp starting on Friday. Its $0 and its really high quality. Itll be a new video everyday from 11/15 to the end of the year\nThank you for doing this. Please Dont mind the haters\nRemindme! 5 days\nYou know the field you work in is cooked when people aren't making enough money doing said work and instead need to sell courses doing said work.\nImagine thinking theres going to be less data in the future\nThanks for this! This style of learning with one video per day seems to be the perfect way for me to fit in DE learning with my regular university studies. I have a question though. Is there any prerequisite knowledge required for this bootcamp other than some understanding of Python and SQL/DBs?\nWhat is all about these remind me 6 days? Is it going to be free?\nIt says free in the title fam\nAppreciate you making the content accessible on YouTube, I'm excited to check out the series!\nThank you zach :)\nexcited because this is like actual useful content unlike your IG \nTry teaching DE in 90 seconds. Its hard as fuck\nNah, no hard feelings but half of it is like travel and hanging out with x y z.\nOh no, not content creators being human people! They should all dedicate their lives 24/7 to educating you directly!\nSigned up for data information and educational content. Not daily vlog and lifestyle, mate\nYeah. I mostly gave up on trying to make shorts about 6 months ago because I recognized the value is lower. I only do collabs with Delia and Maddy and Fritz now\nHaving 150k on IG is a plus for dating though\nWeird flex but ok\nDon't be a dick\nRemindME! 6 days\nI will be messaging you in 6 days on [**2024-11-16 01:53:55 UTC**](http://www.wolframalpha.com/input/?i=2024-11-16%2001:53:55%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1gnor9c/launching_a_free_sixweek_data_engineering_boot/lwchgc7/?context=3) [**24 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1gnor9c%2Flaunching_a_free_sixweek_data_engineering_boot%2Flwchgc7%2F%5D%0A%0ARemindMe%21%202024-11-16%2001%3A53%3A55%20UTC) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201gnor9c) ***** |[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)| |-|-|-|-|\nWas aware of this from X. Felt somehow surprising to see it pop up again on reddit. I think I grew accustomed of the one-way-ratchet in that professionals I knew as college students are mostly on X now, having performed a sort of Digg 2.0 migration out of reddit. Hence the feeling of surprise of professional content seen first on X going the other direction haha.\nRemindME! 6 days\nRemindME! 6 days\nFantastic! Im learning to code so Im not sure Im ready. Would these courses be available indefinitely?\nIt's on YouTube so yes!\nRemindME! 6 days\nRemindme\n!remind me 5 days\nRemindme! 5 days\nRemindme! 5 days\nthanks Zach\nRemindME! 6 days\nRemindME! 6 days\nRemindME! 5 days\nRemindME! 6 days\nRemindME! 5 days\nRemindme! 5 days\nRemindME! 6 days\nRemindME! 6 days\nRemindME! 5 days\nRemindME! 6 days\nI'm excited too... Thank you !!\nRemindME! 6 days\nRemind me! 6 days\n!remind me 5 days\nRemind me! 5 days\nRemindME! 6 days\nRemindME! 6 days\nRemindME! 6 days\nRemind me! 5 days\nRemind Me! 6 days\nRemindME! 6 days\nHow much hours in content will it be ?\nOk 90+ h is crazy\nRemindME! 6 days\nRemindme! 5 days\nRemindME! 6 days\nRemindme! 5 days\nWow, letsgo!\nRemindME! 6 Days\nRemindME! 6 days\nRemindME! 6 days\nRemindME! 6 days\nThankyou . Looking forward to it\nREMIND ME! 6 DAYS\nWow, this is awesome! I am so excited. I have been waiting this course from July. Thank you for making the wait over "
    },
    {
        "post": "/r/dataengineering/comments/1gugtv6/stop_stealing_my_teams_work/",
        "comments": "Ahhh you ran into a manager who just realized his job (and that of his entire team) could be eliminated by a good DEYou are not the mystical AI but instead, a flesh and blood human with less years of experience (?) than him. You are the enemy in his eyes.\nNo manager in this corporate environment would say this. They can't risk leaving any trace of being absent and would instruct subordinates to keep it secret. This could lead workers to contact higher management, potentially prompting restructuring and layoffs that threaten the manager's position.\nMost relatable post ever. The amount of times people think their manual excel process is just too confusing to automate absolutely boggles my mind.\nMy first thought when someone says that is that theyre cooking their numbers.\nYouve just helped me piece together the root cause of an error we just couldnt seem to place, thank you\nSeriously? No worries :)\noh boy I have a \"data scientist\" colleague who defends his manual copy/pasting excel to death. The times when we talk about automating his process, then things just become extremely defensive and awkward, also need new co-workers.\nPlease dont insult data scientists. You have a data entry colleague right there.\nIts mostly been true in my case, since the excel is popuoated through phone calls.\nAhahahahaha \nYou should be talking to YOUR boss about this, not the team you are ostensibly replacing.\nTell your boss youve just identified a massive opportunity for corporate cost cutting.\nThe only way to sell this to the people it's for, is by highlighting all the other tasks they can now perform that they didn't previously have time to do. If you can sell it as a mechanism to automate the boring grunt work so they have time for fun/interesting works you'll make plenty of friends.\nSo the issue with that is we work under a matrix management structure. Just the DE and IT devs work this way. There is on paper boss, Director, met him 3 times since starting, very aloof and always pressed for time, not the kind of person you reach out to for a friendly teams call. He is who I submit my leave requests too, and whose admin approves them. Ha. Then there is my senior, the guy who trained me, who I go to for any technical help etc, he was aware of it since I had asked for a 2nd pair of eyes to look it over before I presented it. He was encouraging, but also found it hilarious and told me about them raking in the OT after the fact. He's not that much more senior than me, and certainly doesn't have the seniority to \"have my back\" as it were against this senior manager. Then the fun bit, whichever department head whose projects you're working on is kind of your boss for the duration of that project. In between day to day DB updates and generally maintaining the ERP we get put onto these mini secondments where we go in, get told the problem they want fixing and \"engineer\" a solution. Agree timescales, report back on progress all that kind of shit. So for creating the initial report this guy was my boss for about 3 days. But this is a good few weeks after that and I was in between projects and did it off my own back. It does make it difficult to know where you stand in the company, and seniors on my team are constantly at loggerheads with seniors in IT, then there is like a management chasm for the DE team specifically because we report to this director who is seemingly uninterested in managing us, our worth is mainly communicated back through department heads. It does have its advantages, we get to work out who does what ourselves and can be autonomous when time allows, it's a good team. Also, I may as well say this here too. The scope of this teams work is not this one thing. They have several responsibilities. I'm far too junior in the org hierarchy to be suggesting what this guy does with his team instead. The way they described it to me was as if it was the bane of their existence, that if only they didn't have to do it they could finally get on top of their workload. So that was my motivation. I didn't set out to make people redundant and would have been a bit more diplomatic if I understood that they do in fact want/need this work. Although I do still think if a pipeline can do what's taking 9 people a significant chunk of the working week + OT in under 6 seconds then it should probably be adopted as the process. It's been good reading everyone's replies though. I'm gonna sit on it for now to see if either the promotion or new job pans out. If neither do I think I'm gonna get all my ducks in a row and start a job search in earnest. Although January is shit for job hunting so I'm hoping to land a role before the Christmas break!\n>It does make it difficult to know where you stand in the company, and seniors on my team are constantly at loggerheads with seniors in IT, then there is like a management chasm for the DE team specifically because we report to this director who is seemingly uninterested in managing us, our worth is mainly communicated back through department heads. It does have its advantages, we get to work out who does what ourselves and can be autonomous when time allows, it's a good team. Yeah this sounds like a shit show.\nIt is a bit, but I've learnt a lot about project management and get the opportunity to work everything from defining scope to the implementation of new processes which is quite rewarding when it works. It also teaches you a lot about how every area of the business works which is less than useless since I don't plan on staying in the industry, but is good for having a nuts and bolts understanding of how the business functions are generating the data you work with. I'd say it gives you good experience of managing relationships and competing priorities but I think the op shows this was a swing and a miss here. It's what I'm gonna say at interview though haha\nYea ... so here's the deal ... you just learned a valuable lesson. You are the kind of person who values mastery ... of domain knowledge, systems, tools etc. And you just learned that this manager and this team do not. They have a convoluted claptrap process that they grok, that rakes in overtime, and most importantly guards them against additional work. They have what they value ... stability. You threatened that just by doing what you always do. But guess what? There's another way to approach this. Frame this same work as a tool for them to check their work as a way to help catch all those big errors and now you are protecting that same stability. It's also collateral. You won't have to dig all that deep to validate old reporting history to have a nice pile of costly fuckups that whole team probably would prefer no one notice. If you like doing this kind of work - you can do a lot of it in most organizations - as long a stakeholders sing your praises. If they aren't interested in using it to check their work or go home early for the weekend ... you can also use it to empower the few people on that team who actually want to do better. Give them the ammo to get the status quo guy fired and when the dust settles you have allies who will sing your praises.\nThis is the best advice\nThis guy leverages.\nHere's a thought: What would happen if you went over his head with the solution? Or if it's part of a wider project group, demo'd it to the whole group? Yes, that manager is never going to like you and it might get a bit political. But you've produced a good piece of work that will save the company a lot of money - the *company* wants it, even though that manager doesn't. And if you're in the sort of company that is open to ideas (or at least sufficiently open to having more money....) this type of work will be seen as a huge win. I'm not saying you necessarily should though, in some situations that will be a career limiting move, it depends on the culture where you work and the individuals involved.\nI don't think going over his head is an option tbh. The gap in seniority is large and above him is director level. He's part of the furniture and im just coming up to 18 months. I need a new job I think. Not for this specifically, the whole culture is a bit off. We are constantly fighting IT and it's very political in general. Annoying because there have been whispers of a promotion. So I keep flip flopping on the next job, this is my first DE role coming from a DA. Got a technical interview later this week for a big salary bump so fingers crossed for that.\nGreat work trying to help out - someone will eventually recognise and appreciate your efforts. All the best for the promotion.\nDude, I've gone over directors' heads[0], just let it fly. DEs are in demand. [0] It was fun being told \"You work for X!\" and responding, \"No, I work for COMPANY\", where X was the director in question. And I have done it more than once, but at most companies you shouldn't have to\nOP. DM me. If your interview doesn't pan out I may be able to offer your something remote, hybrid preferable but if you're a go getter like I think you are I'd be fine with it.\nI'd still go to the director. This guy is way off the map for any kind of professionalism. He basically panicked and tried to threaten you. If you're deadset on leaving, I'd go ahead and risk everything by going above this guy and straight to a director. Maybe give him once last chance (or some time) to change his mind from this initial panic reaction.\nIf you don't even want the job, what's the downside of flagging this with their boss? At worst, you get fired and are forced to find a better job. At best, you become an asset to a director who could make an amazing advocate when going for promotion. At bare minimum, the same presentation should be made to your line manager. If they also don't want to touch it with a barge pole, then yeah, find a new place.\nI suggest writing an email. Address it to the team you are trying to help. Keep it very terse, use easy to follow section headings and one line bullet points, so there is very little friction to reading the email and understanding it. Outline the problem (hours spent manual process, possible human error, opportunity cost, etc), what your process does, how it does it (not too technical), and how it can be used (free up man hours or at least be used to check for errors). Keep the tone bright, friendly, helpful, and professional. No derogatory statements or charged language like total waste of time. Keep it very diplomatic. Then email the whole team doing the work AND HERE IS THE IMPORTANT PART BCC (not CC) this guys boss, and your boss (even if he only signs your timesheet) and any other interested party at the VP/Director level. A good upper management person, will see the email addressed to some other team, notice the BCC, and give it a quick read. Then its up to them what to do with the info. If they do take action to implement your code, you will have plausible deniability that someone else passed it along. The BCC is a bit like a psst you probably want to read this. It conveys subtext that something aint right and they ought to know about it, all without saying any of that.\nTo do this, the person proposing it also needs to be fairly respected and/or senior. If I were OP, Id take this up with _my_ Manager, get their take, and potentially (jointly) go to _their_ Manager to tee it up. If its OP+Manager+Skip level, thats probably the mix to actually gain momentum here. Leave the politics up to them, with respect to this other to-be-automated team.\nThis advice will get OP fired. Work with this manager, and offer to give him and only him this report to help him cross check other people's work or as back up. That way, the report still has use. He becomes your buddy rather than your enemy. Edit: to all downvoters, go ahead and get him fired. We live in a world of people. Relationships matter. My advice plays the long game. It provides a higher likelihood that his work will see the light of the day and will preserve important relationships. But go ahead and burn it all down and trying taking on a fight with someone much more senior than you\nThis is so correct. When working in DE you can easily go in 'optimize-everything-robot-mode' but you can literally delete whole headcounts. and managers need their headcounts (and budget) for their own reason to exist. Working is mostly not about getting work done. I also didn't realize that until I got older. The real world is very different than coding and human relationships matter more.\nFinally, I found the adult in the room. A lot of real-life techie problems are actually human problems, not technical ones.\nMeh, he said he wanted a new job anyway. Playing office politics gets old, and honestly, it feels like you're dealing with spoiled children half the time anyway. Companies exist to make money and if there's a team in place that's just milking overtime knowing that their process is inefficient (and now unnecessary), that seems much less \"adult\" to me than automating this task and potentially eliminating some work for this other team. Just my take, but I've been dealing with Director/VP office politics for a while now, so I'm probably more cynical than most.\ncompanies exist to make money but are run by people, who are optimizing for different things. What you think makes/saves the company money from one viewpoint may be more costly from another viewpoint. This junior employee simply does not know enough to udnerstand what the company is optimizing for. But he sure can save his own job by optimizing for his bosses needs. Unless, OP has a personal significant stake in the company, i will suggest he follows my advice, even if he is looking for another job. He can blow up the place after he finds his new job Its sad that you are dismissing that humans are different, have different personalities, aspirations, and goals as \"play politics\". Maybe stop viewing it that way, and start understanding that different people have different motivations and different things they optimize for. And noone is wrong or right with theirs. Only what you guys have agreed (explicitly or implicitly) to prioritize.\nYou're making a lot of assumptions about both the OP's situation and the motives of senior leadership in many large corporations. If you don't think B.S. politics exist when senior \"leaders\" are given unchecked authority to make terrible decisions with large sums of money, I have doubts about your experience in a corporate environment. I used to think all those people had good intentions, but over time it has become clear that many of the MBA types at the Director/VP levels and above are only interested in the next shiny thing that makes them look good so they can get promoted, or \"leave to pursue another opportunity\" if it fails. They are the ones, in my mind, that are least interested in optimizing anything for the company as a whole and more interested in prioritizing their own self interests above all else. I'm aware that I'm cynical and I'm aware that there are people in senior leadership roles with good intentions, but they are the exception in my experience.\nyeah in corporate you dont steal peoples jobs or automate their work\nYeah, dudes just worried that his entire team has no purpose now and could get laid off if OP automated them out of a job. Not OPs problem per se, but its why the manager didnt find it helpful, lol.\nHere's the \"phrase that pays\". Your job is to help people \"spend less time collecting data and more time analyzing it\". Then it sounds like you're trying to help get people into more valuable work, and it doesn't feel like you're automating them out of a job.\nYep this is how I see it said and done all the time\nI would never want to work at a company like this honestly. It took me a long time to find a company that embraces excellence from new people. I was promoted twice in 8 months and moved to a new team with more responsibility. It took like about 18 years and 7 or 8 different startups to find one that actually does things based on merit.\nI hope I find one one day. I'm a decade in and my current company is a weird collection of factions (each around who? I don't know, but I'm sure it's directors / C suite people). That means VP So-and-So can be an unhelpful ass who gets punted to another team but not fired, and I can get praise and bonuses and promotion talks for reporting honestly that he's an unhelpful ass to my own director. It's nice to be celebrated for honesty and merit in my own pocket of the company, but failing staff with the right friends are just shuffled to different teams rather than fired and I find that very weird.\nStraight to jail\nsomeone here recommended a book called \"Bullshit jobs\". It was quite an eye opener for me.\nif you don't have time, you can just watch that writer's youtube lecture introducing the key ideas in the book. the writer organized Occupy Wallstreet protest. later died of cancer.\nalso wrote Debt: The First 5000 Years and co-wrote The Dawn of Everything. amazing books. Cant believe we lost David Graeber so young.\nOh fuck that. I'd go over his head. What an asshole.\nExactly this. You are employed to serve company not managers. Definitely not a manager who isnt even yours. Also it sounds like the manager and the team is leeching of the company resources, that is money and employees time, weekly, on something that can and has already been automated. The best can happen: you get promoted for saving company lots of money. Department gets released or less overtime, or overtime on other tasks (sure there are other business activities). The worse? You are already looking for a new job. But might want to think how to play that in a next job interview or if you will need a reference. Wondering which industry is this? Sounds like insurance or something similar?\nThe manager most likely used this complicated process to justify: his position, budget and headcount. He had management and finance convinced on how necessary this spend was and how difficult it would be to automate. You come in and disprove that thesis. You do it without involving him and his team (his scope). He now has to explain: why he didnt think of automating it first and if its so easy to automate why was his teams involvement necessary. To make matters worse: you solved it on a Friday :) and he said it was so complicated it requires overtime. Based on your comments, he wasnt convinced that you could automate it. Its making him look really bad. Now hes got to justify his and his teams existence. Hes lost some prestige as well. So its a possible existential threat or just lots of work on his end to justify his groups existence. So totally makes sense why hes panicking and potentially trying to block your process. So you can see the social implications and will have to navigate them. You can try to work with the manager to lessen the blow so hell adopt it by framing it as say a collaboration etc. He might not bite. Alternatively, you can go over his head, but youll probably make an enemy out of him, because he will feel like his back is against the wall and that your meddling in his line of work. Overall, your process is great for business aka finance department will love you, but probably not so great for that managers job prospective.\nIt sounds like you're in a tricky spot. I've definitely been there  had a project where the team needed manual input that I ended up automating with R. The fallout was more about turf wars than efficiency. When automating workflows, its crucial to involve all stakeholders early on to avoid a \"gotcha moment\" that makes them defensive. In your case, maybe present it as a tool to help them focus on more strategic tasks. Also, companies like Aritas Advisors specialize in helping managers adapt to changes like this with strategic financial insights. Sometimes having a third party can make all the difference in reducing friction.\nEvery time you see that manager, give him a look that says you're better than him and his whole team. You are, and he knows it too.\nFirst of all, good on you. Don't listen to the comments saying don't do this. F them. You're making things more efficient and that's a good thing. Is this a possible scenario to have happen? Absolutely. Take it as a learning point, but absolutely do not lose this mentality. I'd be happy to have anyone like you on my team.\nWhat about going one level down, instead of up. Train the guys under the manager up to use the automation techniques you used in the pipeline so that they can do their work after, instead of being stressed out?\nIf this is regular office people, he will burn himself out and there is no reward for him.\nUsually when you want to do extra work (which is weird in itself but ok), you propose your help. Keep in mind that the only things that matter in a corporate environment is the relationships you create with your colleagues. It is not your company, so it is not yours to decide to do the work of other people even if you feel you could do a better job. If you do a great job but make a lot of enemies along the way, it is detrimental to your career (and to the company in the long run).\nWhat can I say I'm a fairly new DE I'm still keen and actually enjoy the work. You're probably right. I wanted the surprised atta boy and didn't really sound it out. I'm a bit socially inept at the best of times.\nHey, don't sweat it. It happens to the best of us. I had a one on one intro with a VP and in that meeting he mentioned to reach out if I ever had any ideas or wanted feedback on something. When I finally did reach out, my immediate manager took it as trying to go outside the chain of command. I hate corporate politics.\nI've done similar as you describe and never had the reaction you got. Some of it got ignored but never attacked. If this leads to fallout for you in the company you should seriously consider moving on to a better org.\nIt's not that weird to want to do extra work. Some people like a challenge or want to solve a problem.\nAt my last company I famously didn't get along with another leader. When I came onboard he had grand ambitions blocked by mindless, yet needed, client facing work and asked how I could help his team. They had incredibly intelligent people doing mindless work. As a side project to learn about this part of the company I ended up automating all their tasks which should have unlocked the power of their team but... they didn't know what to do with themselves. Processes that uses to take two people most of the week now took 45 seconds. Worse, people liked our product better. It was fast, scalable and free of costly human error. What uses to only go to 10 key clients quarterly now went automatically to hundreds of clients monthly. It ended up starting a year long cold war between us whwrr he tried to manage me and i ignored him. It only ended when he was let go simply because he didn't know how to pickup those ambitions and refocus the team. Once he left, that's exactly what we did. I'd run this up your chain. It's not on you to help them reinvent themselves and people hate change... but you have a huge proof of the value you can deliver.\nDon't feel dejected with what you've achieved. That manager complained about the amount of workload his team has to do, you gave him a working solution. It is NOT NORMAL for that particular manager to be unappreciative of the solution. Because the whole point of IT projects especially data projects is to reduce/eliminate repetitive manual labour so that actual humans can work on difficult and tricky work that can't be achieved with automation. It is not your responsibility to look after that manager's team and their jobs. TBH you probably helped them realise how easily replaceable they are and they need to find projects/work that can't be automated so easily. If they keep up with their current ways and stick their heads in the sand it is only the matter of \"when\" that they will be replaced. Maybe have a 1 on 1 with that manager and tell him it was not your intention to \"show off\" and devalue their work, it is just a demo to show what DE can do to help his team reduce overtime and his team can now focus on something else that isn't boring and repetitive which is good for the company. If he is still being an asshole about it even after showing your intentions then this guy and this company culture will be why this company will eventually go down.\nPeople are coming the same realization in a lot of sectors. We have a lot of reluctance from people working with us because automation could replace them.\nI mean lets be honest majority of peoples jobs can be automated. Reality is we are threatening their income. Honestly Im a bit pessimistic as I think more automation will lead to more wealth inequality but its inevitable and required for progress.\nFirst time ? How do you think incompetent people survive in IT ? :)\nI think important part for you is to avoid professional deformation. Stick to your values there will be another job where your approach will be rewarded and appreciated\n> Then he asks me into a meeting room and tells me very clearly I'm not to automate his teams work, and who do I think I am trying to take his teams work away from him. Welcome to workplace politics. > God I need a new job. Correct. At the very least, you need fair representation from somebody who backs you and also has relatively similar levels of authority to the person complaining. If it's any consolation, I've personally never experienced people objecting to work they were doing manually being automated away so they can do other stuff so positions where the culture isn't a shithouse is very possible.\nOh man, been there. We once had a critical person who did all the billing go on holiday and staff got bogged down adding her full time job to theirs. I replaced it with a single button push and a 30 second script/. They promised there was plenty of work for her and I wasnt destroying her job. Turns out she was such a pain in the ass that no one wanted to take her on or retrain her, and she came back to a redundancy. A decade later and I still feel miserable about it.\nIt's cool that you did it but you have no self awareness or emotional intelligence if you expected him to be hyped about it.\nDon't be that guy. No one asked you to do this. You wanted a pat on the head for being clever and didn't think about the jobs you put at risk. I'm not saying you were intentionally trying to get anyone fired, but take this as an opportunity to learn. Not every problem needs to be solved. If you had suggested a partial automation that would have made their job easier instead of fully redundant, it would probably have been more well received.\nNah. Hard disagree with this. OP solutioned something that to the company is valuable. He just ended up presenting it to the person who would lose their job\nAgreed - I'm in a similar position in a hospital. Would rather things take longer than they need to with nurses doing glorified data entry to justify bums in seats rather than cut the chaff and save public healthcare some money that could be redirected to better patient care. Nope, need 15 nurses chasing their own tails or colour shading cells in excel.\nBeing in the US, I was with you until the redirected to better patient care part. So I backed up, caught the public and then bums in seats and all I really need to know is if there really is an impossible amount of nurses color shading excel cells in Sudbury.\nWhere is Sudbury? I wouldn't call it an impossible amount of nurses but if you have a team of nurses with outdated data/work principles, such that you could easily automate the work of say, four of them, then don't they have four nurses too many? Especially when every year there are cuts to funding public healthcare because the state government is broke.\nTake it to your boss.\nThis career is full of weird moments. Im trying to enjoy their irony nowadays\nPretty normal. You got bit by human nature. I got soft fired by making my teams outperform other teams, created by another director. This will be the reality always in this company. If you can use their stupidity for your relaxation, do it. Otherwise try elsewhere.\nId email the CEO lmao wonder what his opinion would be\nI've learned the hard way from scenarios like this to not do stuff unless it's actually asked of me. The politics aren't worth it\nWhat tech;stack;and libraries did you use for this?\nI'm a little more passive aggressive so I'd probably publish my work as an API that Excel can consume, and do everything I can to skip a \"magic spreadsheet\" into their workflow. Once someone organically discovers they can get it to do all the calculations by hitting refresh there will be no putting that cat back into the bag.\nThis sounds like a classic 20-60-20 change management issue. Twenty percent of people are actively engaged in improving things. OP sounds like they are in that cap, because if you are actively looking to get better then you'd assume everyone else would be. The sixty percent are those who need to be convinced of the improvement. And finally the last twenty are just happy with the status quo. Without organisational support, you'll never get these folx on board. So projects for them should be viewed more as practice than hoping for change. The manager sounds like they could have been in the sixty, but the panic pushed 'em into the last twenty. The solution you presented is still correct, the sell is what failed. It might be helpful to convince them of smaller changes and focus on what they could do with the free time. You're saving time so the team could then add X on top. Imagine if you hated the tedious nature of your job and someone just said \"you don't have to do that anymore\" the panic of whether you will still have a job will pop in. So you gotta meet that panic by showing what they could do with the free time instead. Make the new possibilities fulfilling and they will be more likely to give up the tedium. But definitely don't go above the manager's head. And if invited by a more senior person to improve that team, revisit the convo with the manager. \"Y asked me to look at this, previously you seemed unhappy with what I did so how can we get to a middle ground that keeps you and your team engaged?\"\nIve actually lost my job doing something like this, being too good.  I was angry but thankful at the same time. If your boss doesnt appreciate the work then yes, you need a new job. I gotta say its relieving to hear Im not alone in experiencing this.\nAt least you didn't get fired!\nThis is my favourite part about being a data engineer. Automating people out of their jobs and then being incredulous as to why they would be upset about that.\nI have a colleague who was tasked with finding opportunities for intelligent automation in our org. He'll be the first to tell you the problem isn't the technology, it's the politics.\nNo good deed goes unpunished\nYou took it to the wrong person... He doesn't see your win, because he is a MAN-ager... he gets money for MAN-aging... the clue is in the name... It's not AUTO-aging... it is MAN-aging... if there is no manpower required, there is no need for him. If he is too stupid to realise he could implement and keep hush about it whilst everybody keeps their pay checks, then he is too stupid to have a job, take it over his head if you value your solution. Keep it quiet if you value other people's jobs.\nHaving worked at both a large investment manager and a smaller fintech companies, i'm always baffled by the amount of processes that could be easily automated or at least significantly improved by someone with even a modicum of programming knowledge. But at the same time, there are countless people that regularly take home paychecks because these processes are currently inefficient and require man power, and if you cant get them to change, sometimes the juice isn't worth the squeeze and you're better off trying to build cool things elsewhere. It is what it is.\n@u/NotEAcop TLDR- not sure which country/state/city youre at. Get contract/freelance jobs to further hone the skills. Good luck with your upcoming interview. If you want to maintain your relationship at current company - go back to the manager and share a different plan that would roll out the same thing in different phases. Showcase efficiency over 3 quarters to bring down the overtime to near zero. Pick and choose the right metrics to help his team be around. Message me if you need to discuss more. Good luck \nFight, flight, or make friends. This part, the presentation, is about negotiation, not engineering. Try to come at him again, but instead of focusing on your engineering, focus the topic on how the thing you built can help him look good to his managers. Emphasize whatever makes HIM shine, and not yourself. You WILL be recognized, but this moment of getting this solution over to the other side, that is on HIS recognition; he is the leader of his team, not you. Give him what he truly wants: a continued existence. He doesn't care about your solution more than he does his continuity as a manager. Tell him to pitch it like it was his idea. Perhaps you can spark a change in culture. And if this sounds manipulative, it is, because that's fucking human nature. You can use this type of innocent manipulation for the betterment of your company and, thus, yourself. The lesson here is: MAKE FRIENDS ESPECIALLY WITH MANAGERS. Make him look good, and he'll make you look good.\nKeep going with this approach, if it doesnt pay off in this company it will for sure in the next one!\nunfortunately thats how most teams and humans work. Not just at work but everywhere. Changing job will not solve your problem. Good thing is you are doing the right thing. Dont give up, there must be ten other problems you can solve with that mindset in that work place. There exists a piece of work especially closely related to ones territory that could make them react with hostility. Sometimes, it is best to keep the solution to yourself and improve your quality of life for a while before sharing with others.\nSounds like that manager is more concerned about the appearance of being busy, probably how he asserts the need for himself and the team around the workplace. Like others in the comments, I'm petty and would be going over his head dependant on how the rest of the team feel about it. If they like doing the OT then fair enough, if not it sounds like he's keeping them busier than they have to be. You could always have a private chat with his superior to show what you made and discuss the possibility of carving out a role to do it. It won't only be that team/department that can benefit from those skills.\nLMAO, the fact you think its weird he would be panicked or annoyed is hilarioushow old are you? youve got to be a new grad junior, right? hahaha ignorance is astounding\nYou should demo this to their boss. Time to get rid of that useless team."
    },
    {
        "post": "/r/dataengineering/comments/1gud4jq/what_are_the_best_books_to_read_and_grow_as_a/",
        "comments": "Have you read design data intensive applications? Thats number one imo\nYoure right, thats a great book \nCan you give more context as to why? I often hear it cited , but feel it was like reading a generic business management book.\nDo you mean DDIA felt like a generic business management book? The book goes into technical depth on different topics. Are you thinking of a different book? My experience reading The Fundamentals of Data Engineering made me feel similar to you.\nWhat do you mean by business management? Its data topics in depth and not only gives the view point how and where the different technologies rooted from but also talks about optimisation techniques. For me it was always difficult to understand the what is transactional data, what does oltp vs olap exactly mean until I read this book. But its a heavy book and takes quite some time to read through.\nThe Art of War for plotting against your coworkers.\nI think 48 laws of power would be more appropriate\nJokes aside, this really is a powerful book. So is *The 33 Strategies of War*. These helped my confidence in a management role when working with very senior non-technical people, often of questionable character.\nanother solid recommendation\nHow to win friends and influence people\nRules of Acquisition\nThe data warehouse toolkit - Ralph Kimball\nThis book is probably the largest single resource contributing to my income in the past 10 years or so.. Funny to think about it that way \nFirst time I read this I thought it was so boring. Now that I actually solve these problems on a daily basis I would never part with it. I do think it needs a new edition, but nothing else out there has come close to replacing it yet.\nWhat's your tech stack?\nIt doesn't matter, the book is pretty much technology agnostic (contains code/sql samples written for some old af sql server though). I've worked over the years with various projects involving for example Azure + DF + Snowflake, AWS, GCP BQ & Dataform, Onprems like SQL Server+SSIS, Teradata+Informatica, damn also MongoDB + NodeJS + Python. Tools are secondary, priority is understanding what you're trying to solve.\nIt is indeed technology-agnostic, but strongly oriented towards analytics applications, which is only one part of the data engineering landscape. Still a must-read, but it's important to see how much it matches your usecase.\nTbh its not a book people read in the teaditional sense. You use it to solve problems and use the examples in the book to replicate your own solutions - not read front to back like a novel or even a textbook. Sorry in advance for the pedantic response lol. Not trying to be a troll, but I remember trying to read it and talking to some engineers about literally trying to read the book and getting laughed at earlier on lol But agree, this book is super helpful.\nI mean true, but theres no reason OP shouldnt get it. I mostly just like having it handy and i havent read it cover to cover, but it explains concepts very well and is a great reference when I need it\nCan you elaborate? What is the learning outcome from the book?\nData warehousing and dimensional modeling\nWhich edition would you recommend?\nMy old architect adamantly recommended the 2nd edition. Personally I own the third. I dont really know the difference\nSome that aren't technical / in depth but helped with soft skills, DE management, explaining cloud concepts, etc. \\- Difficult Conversations by Bruce Patton, Douglas Stone, and Sheila Heen. I have found that reading this book and applying the concepts at work (as well at home) helped me have the hard conversations I had been avoiding and redirect mine and my team's career. I truly wish I would've read it earlier and would consider it essential. \\- Turn the Ship Around!: A True Story of Turning Followers into Leaders by David Marquet. If you're just starting out in DE / any career, you're probably looking to your senior / leads / etc. for advice and management. This book can be read by you alone, but it's best when done as a team. It's essentially about making all members of a team feel like leaders and that they can contribute value rather than directly looking to one person to make all the decisions. This is great for individual / team morale, OKRs, etc. \\- Explain the Cloud Like I'm 10 by Todd Hoff. If you use cloud computing or want to, you will most likely need to explain and pitch it to others. People are busy in their jobs and often don't want to change environments that already work, even if it's for long term gain. As an example, pretty much every cybersecurity person I've interacted with at a corporation that uses on premise storage / computing does not like cloud computing. They do not like it and they do not want it because they do not understand it. This book (as well as the difficult conversations one) allowed me to move environments to AWS / Databricks at two different jobs with huge benefits.\n\\+1 difficult conversations, a book i try to re-listen to every couple of years\n\"Data and Goliath\" if you want to feel some social responsibility in your role.\nFollow podcasts like the data engineering show hosted by Tobias Macey. This will keep you updated on the latest and greatest happenings in the DE world. Of course follow other advice here on books like the Kimball groups to come up to speed with DE.\nWhat younger generations (which is 90% of this sub) dont understand is dont run after the hype. What makes you valuable is how much more profit you bring to a company. And how do you do that? Solve actual problems instead od copy cat podcasts, yt channels etc. that are either sponsored by a saas or follow the ai hype. Go out and find projects that interest you. Learn as you do them.\nSo much this. Everyone thinks they need to learn how to sprint when they haven't learned how to tie their shoes. Learn how to deliver value to your organization and within that organization's goals (growth, profit). Don't try to be a Spark/Kafka PMC on day one. Eventually, it will all come into focus.\nLets Get Real or Lets Not Play - Stakeholder management. It will help you in countless ways that arent immediately obvious. Designing Data Intensive Applications - Its the meat and bones of the tech stuff. Enjoy.\nStart with Fundamentals of Data Engineering, Data Management at Scale and the DAMA DBOK.\nOh interesting. Haven't read it yet, what's up with Fundamentals of DE?\nThese books serve completely different purposes\nIts not a grift if you do actually need to learn what the book teaches. Which is probably half this sub.\nOK, serious answer now. The hard truth is that books and blogs will only get you so far. You have to get into the thing and start using it and learning how things work and making a metric shit-ton of mistakes. That is how you grow at being a data engineer and, later, a data architect. This takes time and there are very few short cuts. Focus in on SQL to start. If your current product supports ANSI SQL, all the better. Get to know it like your life depended on it and delve deep into the documentation of your product. Product extensions to SQL are good, but by their nature they will vary from product to product. Don't hang your hat on them but get acquainted with them. You'll know you are on the right track when you discover some new feature you didn't know and want to share it with your peers. All this is just step 1. This question gets asked quite a bit here. I have a reply that is worth the trouble for you to figure out what [the next steps](https://www.reddit.com/r/dataengineering/comments/1gfgl02/comment/lujz7bg/) are.\nHello, thank you so much. I'm currently in the quest of landing my first job as junior DE (i'm a career shifter) started the vast journey last October after I finished my CS50x Introduction to Computer Science. Saw some roadmap in YT in how to become one, and these are the steps they recommend. 1. SQL 2. Code 3. Data Warehousing & Modeling, 4. Data Pipelines 5. The Cloud 6. Git and Version Control. I'm simultaneously learning the SQL and the Coding part. steps 1 and 2. Though in CS50x we tackled some coding (C, Python, JS) and sql (sqlite) but it is just a introduction. Decided to delve deeper in SQL and Coding. I'm currently reading the; Practical SQL by Anthony DeBarros (PostgreSQL) and Python Crash Course by Eric Matthes. Fortunately, if I'll finished the steps 1 and 2, where can I learn the succeeding steps (3-6), what are the books for it? For now, I can't see myself enrolling in a online course because I can't afford the payment. That is also the reason why I chose CS50 since they offer a free online courses. Thank you.\nI curate a little list of [Books on Data Engineering](https://www.ssp.sh/brain/books-of-data-engineering/), but I'd say the mentioned Kimball and Data-intensive by Klepmann are great. Then you can always go deeper in any direction. I am writing an online book, too; the beginning is free (you find it on the list too).\nThe Software Engineer's Guidebook - a more casual, high level read about the housekeeping side of the job, applicable to any engineering role. Seems like a great reference to navigate and plan a career.\ndepends on your focus: - intro: fundamentals of DE - database: database internals - data systems deeps: designing data intensive apps - data warehouse and modeling: data warehouse toolkit - spark: learning spark - spark: definitive guide May you need to pick what you need even on chapters level and come back to parts once you interested in, also take a look about short-long memory and how not to forget what you read easily, and finally take any chance to practice what you read. Good luck\nThinking in Systems by Donella Meadows\nMy little Pony Island Adventure /s\nAre there any online sources, open source books for DE?\nThe ones that move you to SWE, MLE, AIE, or dev ops.\nYou guys can read?\nAny book on python and the Unix command line. Sed, awk, bash, and python are the skeleton that your data engineering muscles grow on.\nMythical man month\nBooks are boring for me. I follow DE blogs on Medium and listen to podcasts.\nCan you give me some examples of blogs and podcasts? The best ones you know!\nI liked this episode much: http://softwareengineeringdaily.com/2020/01/10/slack-data-platform-with-josh-wills/\nGet medium premium subscription. Lot of things covered there.. then ctrl+alt+azure podcast is good.. there is one called data engineering podcast.. i am not up to date on this one\nIf you are already in the business I'd recommend switching jobs to get in touch with really large data sets (say 1 PB every day). Most of the knowledge was learned from experience, not books, as far as I know.\nI am in the same camp as you. The joke is that you don't get out of bed for less than a billion rows.\nYep unfortunately most of those jobs I can think about are from the Ads business...\nData Engineers are growing books these days?"
    },
    {
        "post": "/r/dataengineering/comments/1gjme27/duckdb_gsheets_query_google_sheets_with_sql/",
        "comments": "Read and write Google Sheets with DuckDB Docs: [duckdb-gsheets.com](http://duckdb-gsheets.com) Source code: [github.com/evidence-dev/duckdb\\_gsheets](http://github.com/evidence-dev/duckdb_gsheets)\nToday I'm working on some customer facing analytics powered by DuckDB, so very cool!\nVery cool!\nneat!\nCool stuff! DuckDB is my DE Swiss Army knife.\nPlease dont show small companies this. We will be right back to one spreadsheet used as the company databse.\nDoes this just query google sheets or does it modify it as well?\nboth are supported modify / write: [duckdb-gsheets.com/#write](http://duckdb-gsheets.com/#write)\nMy last company used G sheets for literally everything, this would have been so nice lol\nHow does it read columns with cells that have types which are not uniform?\nit will attempt to infer from the first row. if the first row is numeric and subsequent rows are varchar i think it would fail\nI think a safer approach could be to check all of the values and cast based on the most generic type across that column.\n> I think a safer approach could be to check all of the values and cast based on the most generic type across that column. The safer and faster approach would be to cast everything as varchar.\nthis is true, i suppose you could let the users do the cast once they had read it into duckdb\nsafer but more expensive"
    },
    {
        "post": "/r/dataengineering/comments/1gcgz4g/best_resources_for_data_architecture_data/",
        "comments": "After 28 years in the data management field, I have been in every role I could work. Data architecture and data modeling is IMO equal parts art and science. Yes you can learn a few fundamentals through books by authors like Kimball, Inmon, David Hay, etc but you learn a lot from actual work experience. Because, no one can capture in a book the sheer variety of design situations you can encounter in real life and how the design will vary not just based on technical aspects but also based on financial, people skills and biases in a particular situation. I highly recommend learning through doing it. Good luck.\n> Because, no one can capture in a book the sheer variety of design situations you can encounter in real life and how the design will vary not just based on technical aspects but also based on financial, people skills and biases in a particular situation. This is important, a core idea you need to learn in any tech job (especially data) is to *understand* the business and how it functions. If you can truly understand the business case and have even a basic understanding of database designs you'll be 10x as useful as someone who can recite a textbook from memory but have to have everything in business explained to you. I'd even argue that a lot of the complexity that advance data designs run into is because someone along the doesn't understand the business side enough to simplify the request/process.\nI'll go against the grain and say designing data intensive applications was a bit low level for my tastes as a data engineer. But it was nice to know how the database works. I'd recommend Kimball Data Warehouse Toolkit. It's fundamental and a deep understanding of it is required before you move on to other concept.s\nI would be interested in understanding actual applicability of Kimball DW designs in todays world - which seems to be converging towards columnar storage formats with day 1 metadata/governance requirements.\nYou're right, it's not always applicable. Can depend on your BI tool or end use case but knowing it certainly isn't wasted time. Even if you understand why you're not using it.\nIt's still the standard for serving a BI tool and that likely won't change any time soon. Nearly anything other than BI would be better served with a different design.\nI just bought this after reading your comment. Hadn't heard of it before and am looking forward to reading it!\nIt's a very dry read to be honest but good for understanding dimensional modelling\nGood to know. So much work and training is focussed on holding together the convoluted tech stack these days that I rarely have to think about the modelling. I'm hoping to start going for roles that are more modelling focussed so sounds like a good fit.\nSearch for dbt roles or roles titled Analytics Engineer. it's a modelling focused subset and what I actually do\nI'm with you. DDIA is the most misguided recommendation to data engineers\nIt's misguided for junior and mid. I think it's useful for senior+ but only because it helps reasoning about systems.\nUnless you are using the Inmon approach. :)\nStrong agree on DDIA. It's important, I think engineers should read it, but certainly not as a foundational book. It's just too low level. Okay great consistency and consensus in DDIA is pretty divorced from actual use-cases (like say Cassandra/Scylla NoSQL store).\nJust curious, why would you say it's not a foundational book? I always heard it mentioned like it was some kind of bible of principle's for (data) systems engineering. I am currently reading it and finding it very interesting\nDDIA is not one of the first 2-3 books you should read as a data engineer. As others have said it's a bit too low-level. It is interesting, absolutely, and useful when trying to reason about certain systems, but I would argue it's not especially helpful at the junior level. The sections on replication, consistency, and consensus, are not especially practical. E.g. great the company architect has set up the NoSQL store with quorum reads. You need to know what that means, not what the other options are and their various trade-offs etc. The put it another way: DDIA is (generally speaking) a book about the *theoretical* basis of systems design. The general motivations and general trade-offs and some solutions. This is a slight exaggeration of a comparison but I think root of it holds: if you have a CS background but it's like telling your junior engineer they need to study the theory of computation (e.g. Sipser's intro, or Arora's Computational Complexity or whoever) while they're still working on basic programming and basic algorithms.\nGot it, thanks for your input\nFundamentals of Data Engineering Designing Data-Intensive Applications Designing Machine Learning Systems\nJoe Reis is also writing a data modeling book now and has an online data modeling community/substack if you are interested in that route. Kimball and Inmon are still relevant today even though they are very old as the concepts may inform even non-traditional models. MDM is often more business facing, arguing with stakeholders over definitions and cataloging the results.\nWhere's his community? Id love to join\nPractical data modelling on substack\nI'd also add that Joe has his own separate substack as well, I'd recommend people to get both\nWhat's the name of the book?\nPractical Data Modeling. [https://practicaldatamodeling.substack.com/](https://practicaldatamodeling.substack.com/)\nThe designing data intensive applications is a good one to get up to speed with certain concepts. I dont know how much value it will add if you already have experience and have passed certain certifications\nThanks! I will check the book. For certifications, I only passed Databricks courses, namely DE Associate and Spark Developer. The rest I just mentioned to be listed as suggestions. Do you also recommend any certification?\nCertifications depend on the why. How does it fit into your career goals? Are you looking to maximize future job possibilities? Or is it specialization you are going for? Think of yourself in 5 years time, where do you see yourself? Now create a roadmap which leads you to reach your target and you will see that many questions posted here will be answered\n[https://www.databass.dev/](https://www.databass.dev/) Honestly I am so surprised no one has recommended this book yet. We as data engineers live and breathe data systems (relational and otherwise) and knowing the internals seems to me an essential idea.\nGood resources cited here so far and I agree with the learning whole doing and domain expertise comments. I'd also recommend Dave McComb's books on data-centric architecture: Software Wasteland and The Data Centric Revolution. I've found the framework that McComb outlines is helpful for reducing complexity, hard to put into practice, but a good North Star. Zhamak Denghani's book, Data Mesh, is also a good read that goes into the socio-technical aspects of data architecture and how to design organizational structures that enable good data management practices.\nRegarding data modeling, apart from the \"Data warehouse toolkit\" others have mentioned, I have really enjoyed the \"Agile data warehouse design\" book by Lawrence Corr"
    }
]